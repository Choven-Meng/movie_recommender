{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from tensorflow.python.ops import math_ops\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def _unzip(save_path, _, database_name, data_path):\n",
    "    print('Extracting {}...'.format(database_name))\n",
    "    with zipfile.ZipFile(save_path) as zf:\n",
    "        zf.extractall(data_path)\n",
    "\n",
    "def download_extract(database_name, data_path):\n",
    "    \"\"\"\n",
    "    Download and extract database\n",
    "    :param database_name: Database name\n",
    "    \"\"\"\n",
    "    DATASET_ML1M = 'ml-1m'\n",
    "\n",
    "    if database_name == DATASET_ML1M:\n",
    "        url = 'http://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
    "        hash_code = 'c4d9eecfca2ab87c1945afe126590906'\n",
    "        extract_path = os.path.join(data_path, 'ml-1m')\n",
    "        save_path = os.path.join(data_path, 'ml-1m.zip')\n",
    "        extract_fn = _unzip\n",
    "\n",
    "    if os.path.exists(extract_path):\n",
    "        print('Found {} Data'.format(database_name))\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Downloading {}'.format(database_name)) as pbar:\n",
    "            urlretrieve(\n",
    "                url,\n",
    "                save_path,\n",
    "                pbar.hook)\n",
    "\n",
    "    assert hashlib.md5(open(save_path, 'rb').read()).hexdigest() == hash_code, \\\n",
    "        '{} file is corrupted.  Remove the file and try again.'.format(save_path)\n",
    "\n",
    "    os.makedirs(extract_path)\n",
    "    try:\n",
    "        extract_fn(save_path, extract_path, database_name, data_path)\n",
    "    except Exception as err:\n",
    "        shutil.rmtree(extract_path)  # Remove extraction folder if there is an error\n",
    "        raise err\n",
    "\n",
    "    print('Done.')\n",
    "    # Remove compressed data\n",
    "#     os.remove(save_path)\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    \"\"\"\n",
    "    Handle Progress Bar while Downloading\n",
    "    \"\"\"\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        \"\"\"\n",
    "        A hook function that will be called once on establishment of the network connection and\n",
    "        once after each block read thereafter.\n",
    "        :param block_num: A count of blocks transferred so far\n",
    "        :param block_size: Block size in bytes\n",
    "        :param total_size: The total size of the file. This may be -1 on older FTP servers which do not return\n",
    "                            a file size in response to a retrieval request.\n",
    "        \"\"\"\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found ml-1m Data\n"
     ]
    }
   ],
   "source": [
    "data_dir = './'\n",
    "download_extract('ml-1m', data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID Gender  Age  OccupationID Zip=code\n",
      "0       1      F    1            10    48067\n",
      "1       2      M   56            16    70072\n",
      "2       3      M   25            15    55117\n",
      "3       4      M   45             7    02460\n",
      "4       5      M   25            20    55455\n",
      "[[1 'F' 1 10]\n",
      " [2 'M' 56 16]\n",
      " [3 'M' 25 15]\n",
      " ..., \n",
      " [6038 'F' 56 1]\n",
      " [6039 'F' 45 0]\n",
      " [6040 'M' 25 6]]\n",
      "{1, 35, 45, 50, 18, 56, 25}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "users_title = ['UserID','Gender','Age','OccupationID','Zip=code']\n",
    "usersd = pd.read_table('./ml-1m/users.dat',sep='::',header=None,names=users_title,engine='python')\n",
    "users = usersd.filter(regex='UserID|Gender|Age|OccupationID')\n",
    "print(users.head())\n",
    "#print(usersd.head())\n",
    "users_orig = users.values\n",
    "print(users_orig)\n",
    "print(set(users['Age']))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MovieID                               Title                        Genres\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "movies_title = ['MovieID','Title','Genres']\n",
    "movies = pd.read_table('./ml-1m/movies.dat',sep='::',header=None,names=movies_title,engine='python')\n",
    "print(movies.head())\n",
    "movies_orig = movies.values\n",
    "pattern = re.compile(r'^(.*)\\((\\d+)\\)$')\n",
    "title_map = {val:pattern.match(val).group(1) for ii,val in enumerate(set(movies['Title']))}\n",
    "movies['Title'] = movies['Title'].map(title_map)\n",
    "#电影title转化为数字字典\n",
    "title_set = set()\n",
    "for val in movies['Title'].str.split():\n",
    "    title_set.update(val)\n",
    "#print(len(title_set))\n",
    "title_set.add('<PAD>')\n",
    "title2int = {val:ii for ii,val in enumerate(title_set)}\n",
    "#print(title2int)\n",
    "    #title转成等长数字列表15\n",
    "    #将电影Title转成等长数字列表，长度是15\n",
    "title_count = 15\n",
    "title_map = {val:[title2int[row] for row in val.split()] for ii,val in enumerate(set(movies['Title']))}\n",
    "    \n",
    "for key in title_map:\n",
    "    for cnt in range(title_count - len(title_map[key])):\n",
    "        title_map[key].insert(len(title_map[key]) + cnt,title2int['<PAD>'])\n",
    "    \n",
    "movies['Title'] = movies['Title'].map(title_map)\n",
    "print(len(movies['Title'][8]))    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>timestamps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  timestamps\n",
       "0       1     1193       5   978300760\n",
       "1       1      661       3   978302109\n",
       "2       1      914       3   978301968\n",
       "3       1     3408       4   978300275\n",
       "4       1     2355       5   978824291"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_title = ['UserID','MovieID', 'Rating', 'timestamps']\n",
    "ratings = pd.read_table('./ml-1m/ratings.dat', sep='::', header=None, names=ratings_title, engine = 'python')\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load Dataset from File\n",
    "    \"\"\"\n",
    "    #读取User数据\n",
    "    users_title = ['UserID', 'Gender', 'Age', 'JobID', 'Zip-code']\n",
    "    users = pd.read_table('./ml-1m/users.dat', sep='::', header=None, names=users_title, engine = 'python')\n",
    "    users = users.filter(regex='UserID|Gender|Age|JobID')\n",
    "    users_orig = users.values\n",
    "    #改变User数据中性别和年龄\n",
    "    gender_map = {'F':0, 'M':1}\n",
    "    users['Gender'] = users['Gender'].map(gender_map)\n",
    "\n",
    "    age_map = {val:ii for ii,val in enumerate(set(users['Age']))}\n",
    "    users['Age'] = users['Age'].map(age_map)\n",
    "\n",
    "    #读取Movie数据集\n",
    "    movies_title = ['MovieID', 'Title', 'Genres']\n",
    "    movies = pd.read_table('./ml-1m/movies.dat', sep='::', header=None, names=movies_title, engine = 'python')\n",
    "    movies_orig = movies.values\n",
    "    #将Title中的年份去掉\n",
    "    pattern = re.compile(r'^(.*)\\((\\d+)\\)$')\n",
    "\n",
    "    title_map = {val:pattern.match(val).group(1) for ii,val in enumerate(set(movies['Title']))}\n",
    "    movies['Title'] = movies['Title'].map(title_map)\n",
    "\n",
    "    #电影类型转数字字典\n",
    "    genres_set = set()\n",
    "    for val in movies['Genres'].str.split('|'):\n",
    "        genres_set.update(val)\n",
    "\n",
    "    genres_set.add('<PAD>')\n",
    "    genres2int = {val:ii for ii, val in enumerate(genres_set)}\n",
    "\n",
    "    #将电影类型转成等长数字列表，长度是18\n",
    "    genres_map = {val:[genres2int[row] for row in val.split('|')] for ii,val in enumerate(set(movies['Genres']))}\n",
    "\n",
    "    for key in genres_map:\n",
    "        for cnt in range(max(genres2int.values()) - len(genres_map[key])):\n",
    "            genres_map[key].insert(len(genres_map[key]) + cnt,genres2int['<PAD>'])\n",
    "    \n",
    "    movies['Genres'] = movies['Genres'].map(genres_map)\n",
    "\n",
    "    #电影Title转数字字典\n",
    "    title_set = set()\n",
    "    for val in movies['Title'].str.split():\n",
    "        title_set.update(val)\n",
    "    \n",
    "    title_set.add('<PAD>')\n",
    "    title2int = {val:ii for ii, val in enumerate(title_set)}\n",
    "\n",
    "    #将电影Title转成等长数字列表，长度是15\n",
    "    title_count = 15\n",
    "    title_map = {val:[title2int[row] for row in val.split()] for ii,val in enumerate(set(movies['Title']))}\n",
    "    \n",
    "    for key in title_map:\n",
    "        for cnt in range(title_count - len(title_map[key])):\n",
    "            title_map[key].insert(len(title_map[key]) + cnt,title2int['<PAD>'])\n",
    "    \n",
    "    movies['Title'] = movies['Title'].map(title_map)\n",
    "\n",
    "    #读取评分数据集\n",
    "    ratings_title = ['UserID','MovieID', 'ratings', 'timestamps']\n",
    "    ratings = pd.read_table('./ml-1m/ratings.dat', sep='::', header=None, names=ratings_title, engine = 'python')\n",
    "    ratings = ratings.filter(regex='UserID|MovieID|ratings')\n",
    "\n",
    "    #合并三个表\n",
    "    data = pd.merge(pd.merge(ratings, users), movies)\n",
    "    \n",
    "    #将数据分成X和y两张表\n",
    "    target_fields = ['ratings']\n",
    "    features_pd, targets_pd = data.drop(target_fields, axis=1), data[target_fields]\n",
    "    \n",
    "    features = features_pd.values\n",
    "    targets_values = targets_pd.values\n",
    "    \n",
    "    return title_count, title_set, genres2int, features, targets_values, ratings, users, movies, data, movies_orig, users_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_count, title_set, genres2int, features, targets_values, ratings, users, movies, data, movies_orig, users_orig = load_data()\n",
    "\n",
    "pickle.dump((title_count, title_set, genres2int, features, targets_values, ratings, users, movies, data, movies_orig, users_orig), open('preprocess.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>JobID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  Gender  Age  JobID\n",
       "0       1       0    0     10\n",
       "1       2       1    5     16\n",
       "2       3       1    6     15\n",
       "3       4       1    2      7\n",
       "4       5       1    6     20"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[803, 3664, 4038, 4038, 4038, 4038, 4038, 4038...</td>\n",
       "      <td>[15, 11, 1, 12, 12, 12, 12, 12, 12, 12, 12, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[576, 4038, 4038, 4038, 4038, 4038, 4038, 4038...</td>\n",
       "      <td>[0, 11, 14, 12, 12, 12, 12, 12, 12, 12, 12, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>[4787, 1692, 2235, 4038, 4038, 4038, 4038, 403...</td>\n",
       "      <td>[1, 2, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>[4681, 3109, 2038, 4038, 4038, 4038, 4038, 403...</td>\n",
       "      <td>[1, 8, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[1267, 3136, 2712, 4498, 3276, 965, 4038, 4038...</td>\n",
       "      <td>[1, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MovieID                                              Title  \\\n",
       "0        1  [803, 3664, 4038, 4038, 4038, 4038, 4038, 4038...   \n",
       "1        2  [576, 4038, 4038, 4038, 4038, 4038, 4038, 4038...   \n",
       "2        3  [4787, 1692, 2235, 4038, 4038, 4038, 4038, 403...   \n",
       "3        4  [4681, 3109, 2038, 4038, 4038, 4038, 4038, 403...   \n",
       "4        5  [1267, 3136, 2712, 4498, 3276, 965, 4038, 4038...   \n",
       "\n",
       "                                              Genres  \n",
       "0  [15, 11, 1, 12, 12, 12, 12, 12, 12, 12, 12, 12...  \n",
       "1  [0, 11, 14, 12, 12, 12, 12, 12, 12, 12, 12, 12...  \n",
       "2  [1, 2, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,...  \n",
       "3  [1, 8, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,...  \n",
       "4  [1, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()\n",
    "#movies.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_count, title_set, genres2int, features, targets_values, ratings, users, movies, data, movies_orig, users_orig = pickle.load(open('preprocess.p', mode='rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os \n",
    "import pickle\n",
    "def save_params(params):\n",
    "    pickle.dump(params,open('params.p', 'wb'))\n",
    "def load_params():\n",
    "    return pickle.load(open('params.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#嵌入矩阵的维度\n",
    "embed_dim = 32\n",
    "#用户ID个数\n",
    "uid_max = max(features.take(0,1)) + 1 # 6040\n",
    "#电影ID个数\n",
    "movie_id_max = max(features.take(1,1)) + 1 # 3952\n",
    "#性别个数\n",
    "gender_max = max(features.take(2,1)) + 1 # 1 + 1 = 2\n",
    "#年龄类别个数\n",
    "age_max = max(features.take(3,1)) + 1 # 6 + 1 = 7\n",
    "#职业个数\n",
    "job_max = max(features.take(4,1)) + 1# 20 + 1 = 21\n",
    "\n",
    "\n",
    "#电影类型个数\n",
    "movie_categories_max = max(genres2int.values()) + 1 # 18 + 1 = 19\n",
    "#电影名单词个数\n",
    "movie_title_max = len(title_set) # 5216\n",
    "\n",
    "#对电影类型嵌入向量做加和操作的标志，考虑过使用mean做平均，但是没实现mean\n",
    "combiner = \"sum\"\n",
    "\n",
    "#电影名长度\n",
    "sentences_size = title_count # = 15\n",
    "#文本卷积滑动窗口，分别滑动2, 3, 4, 5个单词\n",
    "window_sizes = {2, 3, 4, 5}\n",
    "#文本卷积核数量\n",
    "filter_num = 8\n",
    "\n",
    "#电影ID转下标的字典，数据集中电影ID跟下标不一致，比如第5行的数据电影ID不一定是5\n",
    "movieid2idx = {val[0]:i for i, val in enumerate(movies.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "num_epochs = 5\n",
    "# Batch Size\n",
    "batch_size = 256\n",
    "\n",
    "dropout_keep = 0.5\n",
    "# Learning Rate\n",
    "learning_rate = 0.0001\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 20\n",
    "\n",
    "save_dir = './save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs():\n",
    "    uid = tf.placeholder(tf.int32, [None, 1], name=\"uid\")\n",
    "    user_gender = tf.placeholder(tf.int32, [None, 1], name=\"user_gender\")\n",
    "    user_age = tf.placeholder(tf.int32, [None, 1], name=\"user_age\")\n",
    "    user_job = tf.placeholder(tf.int32, [None, 1], name=\"user_job\")\n",
    "    \n",
    "    movie_id = tf.placeholder(tf.int32, [None, 1], name=\"movie_id\")\n",
    "    movie_categories = tf.placeholder(tf.int32, [None, 18], name=\"movie_categories\")\n",
    "    movie_titles = tf.placeholder(tf.int32, [None, 15], name=\"movie_titles\")\n",
    "    targets = tf.placeholder(tf.int32, [None, 1], name=\"targets\")\n",
    "    LearningRate = tf.placeholder(tf.float32, name = \"LearningRate\")\n",
    "    dropout_keep_prob = tf.placeholder(tf.float32, name = \"dropout_keep_prob\")\n",
    "    return uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, targets, LearningRate, dropout_keep_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义user的嵌入矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_embedding(uid, user_gender, user_age, user_job):\n",
    "    with tf.name_scope(\"user_embedding\"):\n",
    "        uid_embed_matrix = tf.Variable(tf.random_uniform([uid_max, embed_dim], -1, 1), name = \"uid_embed_matrix\")\n",
    "        uid_embed_layer = tf.nn.embedding_lookup(uid_embed_matrix, uid, name = \"uid_embed_layer\")\n",
    "    \n",
    "        gender_embed_matrix = tf.Variable(tf.random_uniform([gender_max, embed_dim // 2], -1, 1), name= \"gender_embed_matrix\")\n",
    "        gender_embed_layer = tf.nn.embedding_lookup(gender_embed_matrix, user_gender, name = \"gender_embed_layer\")\n",
    "        \n",
    "        age_embed_matrix = tf.Variable(tf.random_uniform([age_max, embed_dim // 2], -1, 1), name=\"age_embed_matrix\")\n",
    "        age_embed_layer = tf.nn.embedding_lookup(age_embed_matrix, user_age, name=\"age_embed_layer\")\n",
    "        \n",
    "        job_embed_matrix = tf.Variable(tf.random_uniform([job_max, embed_dim // 2], -1, 1), name = \"job_embed_matrix\")\n",
    "        job_embed_layer = tf.nn.embedding_lookup(job_embed_matrix, user_job, name = \"job_embed_layer\")\n",
    "    return uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将suer的嵌入矩阵一起全连接生成user特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_feature_layer(uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer):\n",
    "    with tf.name_scope(\"user_fc\"):\n",
    "        #第一层全连接\n",
    "        uid_fc_layer = tf.layers.dense(uid_embed_layer, embed_dim, name = \"uid_fc_layer\", activation=tf.nn.relu)\n",
    "        gender_fc_layer = tf.layers.dense(gender_embed_layer, embed_dim, name = \"gender_fc_layer\", activation=tf.nn.relu)\n",
    "        age_fc_layer = tf.layers.dense(age_embed_layer, embed_dim, name =\"age_fc_layer\", activation=tf.nn.relu)\n",
    "        job_fc_layer = tf.layers.dense(job_embed_layer, embed_dim, name = \"job_fc_layer\", activation=tf.nn.relu)\n",
    "        \n",
    "        #第二层全连接\n",
    "        user_combine_layer = tf.concat([uid_fc_layer, gender_fc_layer, age_fc_layer, job_fc_layer], 2)  #(?, 1, 128)\n",
    "        user_combine_layer = tf.contrib.layers.fully_connected(user_combine_layer, 200, tf.tanh)  #(?, 1, 200)\n",
    "    \n",
    "        user_combine_layer_flat = tf.reshape(user_combine_layer, [-1, 200])\n",
    "    return user_combine_layer, user_combine_layer_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义movie ID的嵌入矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_id_embed_layer(movie_id):\n",
    "    with tf.name_scope(\"movie_embedding\"):\n",
    "        movie_id_embed_matrix = tf.Variable(tf.random_uniform([movie_id_max, embed_dim], -1, 1), name = \"movie_id_embed_matrix\")\n",
    "        movie_id_embed_layer = tf.nn.embedding_lookup(movie_id_embed_matrix, movie_id, name = \"movie_id_embed_layer\")\n",
    "    return movie_id_embed_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对电影类型多个嵌入向量做加和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_categories_layers(movie_categories):\n",
    "    with tf.name_scope(\"movie_categories_layers\"):\n",
    "        movie_categories_embed_matrix = tf.Variable(tf.random_uniform([movie_categories_max, embed_dim], -1, 1), name = \"movie_categories_embed_matrix\")\n",
    "        movie_categories_embed_layer = tf.nn.embedding_lookup(movie_categories_embed_matrix, movie_categories, name = \"movie_categories_embed_layer\")\n",
    "        if combiner == \"sum\":\n",
    "            movie_categories_embed_layer = tf.reduce_sum(movie_categories_embed_layer, axis=1, keep_dims=True)\n",
    "    #     elif combiner == \"mean\":\n",
    "\n",
    "    return movie_categories_embed_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie title的文本卷积网络实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_cnn_layer(movie_titles):\n",
    "    #从嵌入矩阵中得到电影名对应的各个单词的嵌入向量\n",
    "    with tf.name_scope(\"movie_embedding\"):\n",
    "        movie_title_embed_matrix = tf.Variable(tf.random_uniform([movie_title_max, embed_dim], -1, 1), name = \"movie_title_embed_matrix\")\n",
    "        movie_title_embed_layer = tf.nn.embedding_lookup(movie_title_embed_matrix, movie_titles, name = \"movie_title_embed_layer\")\n",
    "        #在最后一维增加维度\n",
    "        movie_title_embed_layer_expand = tf.expand_dims(movie_title_embed_layer, -1)\n",
    "    \n",
    "    #对文本嵌入层使用不同尺寸的卷积核做卷积和最大池化\n",
    "    pool_layer_lst = []\n",
    "    for window_size in window_sizes:\n",
    "        with tf.name_scope(\"movie_txt_conv_maxpool_{}\".format(window_size)):\n",
    "            #卷积层的参数：前两个维度是filter的尺寸，第三个是当前层的深度，第四个filter的深度\n",
    "            filter_weights = tf.Variable(tf.truncated_normal([window_size, embed_dim, 1, filter_num],stddev=0.1),name = \"filter_weights\")\n",
    "            #偏置参数，filter的深度\n",
    "            filter_bias = tf.Variable(tf.constant(0.1, shape=[filter_num]), name=\"filter_bias\")\n",
    "            \n",
    "            conv_layer = tf.nn.conv2d(movie_title_embed_layer_expand, filter_weights, [1,1,1,1], padding=\"VALID\", name=\"conv_layer\")\n",
    "            relu_layer = tf.nn.relu(tf.nn.bias_add(conv_layer,filter_bias), name =\"relu_layer\")\n",
    "            #第二个参数过滤器尺寸，第三个参数为步长\n",
    "            maxpool_layer = tf.nn.max_pool(relu_layer, [1,sentences_size - window_size + 1 ,1,1], [1,1,1,1], padding=\"VALID\", name=\"maxpool_layer\")\n",
    "            pool_layer_lst.append(maxpool_layer)\n",
    "\n",
    "    #Dropout层\n",
    "    with tf.name_scope(\"pool_dropout\"):\n",
    "        #在第三维上做连接\n",
    "        pool_layer = tf.concat(pool_layer_lst, 3, name =\"pool_layer\")\n",
    "        max_num = len(window_sizes) * filter_num\n",
    "        pool_layer_flat = tf.reshape(pool_layer , [-1, 1, max_num], name = \"pool_layer_flat\")\n",
    "    \n",
    "        dropout_layer = tf.nn.dropout(pool_layer_flat, dropout_keep_prob, name = \"dropout_layer\")\n",
    "    return pool_layer_flat, dropout_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将movie的各个层一起做全连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_feature_layer(movie_id_embed_layer, movie_categories_embed_layer, dropout_layer):\n",
    "    with tf.name_scope(\"movie_fc\"):\n",
    "        #第一层全连接\n",
    "        movie_id_fc_layer = tf.layers.dense(movie_id_embed_layer, embed_dim, name = \"movie_id_fc_layer\", activation=tf.nn.relu)\n",
    "        movie_categories_fc_layer = tf.layers.dense(movie_categories_embed_layer, embed_dim, name = \"movie_categories_fc_layer\", activation=tf.nn.relu)\n",
    "    \n",
    "        #第二层全连接\n",
    "        movie_combine_layer = tf.concat([movie_id_fc_layer, movie_categories_fc_layer, dropout_layer], 2)  #(?, 1, 96)\n",
    "        movie_combine_layer = tf.contrib.layers.fully_connected(movie_combine_layer, 200, tf.tanh)  #(?, 1, 200)\n",
    "    \n",
    "        movie_combine_layer_flat = tf.reshape(movie_combine_layer, [-1, 200])\n",
    "    return movie_combine_layer, movie_combine_layer_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    #获取输入占位符\n",
    "    uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, targets, lr, dropout_keep_prob = get_inputs()\n",
    "    #获取User的4个嵌入向量\n",
    "    uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer = get_user_embedding(uid, user_gender, user_age, user_job)\n",
    "    #得到用户特征\n",
    "    user_combine_layer, user_combine_layer_flat = get_user_feature_layer(uid_embed_layer, gender_embed_layer, age_embed_layer, job_embed_layer)\n",
    "    #获取电影ID的嵌入向量\n",
    "    movie_id_embed_layer = get_movie_id_embed_layer(movie_id)\n",
    "    #获取电影类型的嵌入向量\n",
    "    movie_categories_embed_layer = get_movie_categories_layers(movie_categories)\n",
    "    #获取电影名的特征向量\n",
    "    pool_layer_flat, dropout_layer = get_movie_cnn_layer(movie_titles)\n",
    "    #得到电影特征\n",
    "    movie_combine_layer, movie_combine_layer_flat = get_movie_feature_layer(movie_id_embed_layer, \n",
    "                                                                                movie_categories_embed_layer, \n",
    "                                                                                dropout_layer)\n",
    "    #计算出评分，要注意两个不同的方案，inference的名字（name值）是不一样的，后面做推荐时要根据name取得tensor\n",
    "    with tf.name_scope(\"inference\"):\n",
    "        #将用户特征和电影特征作为输入，经过全连接，输出一个值的方案\n",
    "        inference_layer = tf.concat([user_combine_layer_flat, movie_combine_layer_flat], 1)  #(?, 200)\n",
    "        inference = tf.layers.dense(inference_layer, 1,\n",
    "                                     kernel_initializer=tf.truncated_normal_initializer(stddev=0.01), \n",
    "                                     kernel_regularizer=tf.nn.l2_loss, name=\"inference\")\n",
    "        #简单的将用户特征和电影特征做矩阵乘法得到一个预测评分\n",
    "        #inference = tf.matmul(user_combine_layer_flat, tf.transpose(movie_combine_layer_flat))\n",
    "\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        # MSE损失，将计算值回归到评分\n",
    "        cost = tf.losses.mean_squared_error(targets, inference )\n",
    "        loss = tf.reduce_mean(cost)\n",
    "    # 优化损失 \n",
    "    #train_op = tf.train.AdamOptimizer(lr).minimize(loss)  #cost\n",
    "    global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    gradients = optimizer.compute_gradients(loss)  #cost\n",
    "    train_op = optimizer.apply_gradients(gradients, global_step=global_step)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#取的batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(Xs, ys, batch_size):\n",
    "    for start in range(0, len(Xs), batch_size):\n",
    "        end = min(start + batch_size, len(Xs))\n",
    "        yield Xs[start:end], ys[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-15T19:34:30.348988: Epoch   0 Batch    0/3125   train_loss = 14.436\n",
      "2018-01-15T19:34:31.492054: Epoch   0 Batch   20/3125   train_loss = 11.001\n",
      "2018-01-15T19:34:32.419107: Epoch   0 Batch   40/3125   train_loss = 7.371\n",
      "2018-01-15T19:34:33.315158: Epoch   0 Batch   60/3125   train_loss = 4.670\n",
      "2018-01-15T19:34:34.178207: Epoch   0 Batch   80/3125   train_loss = 3.093\n",
      "2018-01-15T19:34:35.236268: Epoch   0 Batch  100/3125   train_loss = 2.145\n",
      "2018-01-15T19:34:36.517341: Epoch   0 Batch  120/3125   train_loss = 1.611\n",
      "2018-01-15T19:34:37.518398: Epoch   0 Batch  140/3125   train_loss = 1.373\n",
      "2018-01-15T19:34:38.625462: Epoch   0 Batch  160/3125   train_loss = 1.186\n",
      "2018-01-15T19:34:39.712524: Epoch   0 Batch  180/3125   train_loss = 1.242\n",
      "2018-01-15T19:34:40.782585: Epoch   0 Batch  200/3125   train_loss = 1.478\n",
      "2018-01-15T19:34:41.653635: Epoch   0 Batch  220/3125   train_loss = 1.341\n",
      "2018-01-15T19:34:42.546686: Epoch   0 Batch  240/3125   train_loss = 1.277\n",
      "2018-01-15T19:34:43.447738: Epoch   0 Batch  260/3125   train_loss = 1.316\n",
      "2018-01-15T19:34:44.422793: Epoch   0 Batch  280/3125   train_loss = 1.341\n",
      "2018-01-15T19:34:45.371848: Epoch   0 Batch  300/3125   train_loss = 1.316\n",
      "2018-01-15T19:34:46.370905: Epoch   0 Batch  320/3125   train_loss = 1.345\n",
      "2018-01-15T19:34:47.300958: Epoch   0 Batch  340/3125   train_loss = 1.190\n",
      "2018-01-15T19:34:48.426022: Epoch   0 Batch  360/3125   train_loss = 1.275\n",
      "2018-01-15T19:34:49.555087: Epoch   0 Batch  380/3125   train_loss = 1.262\n",
      "2018-01-15T19:34:50.616148: Epoch   0 Batch  400/3125   train_loss = 1.101\n",
      "2018-01-15T19:34:51.610204: Epoch   0 Batch  420/3125   train_loss = 1.141\n",
      "2018-01-15T19:34:52.592261: Epoch   0 Batch  440/3125   train_loss = 1.246\n",
      "2018-01-15T19:34:53.637320: Epoch   0 Batch  460/3125   train_loss = 1.279\n",
      "2018-01-15T19:34:54.562373: Epoch   0 Batch  480/3125   train_loss = 1.313\n",
      "2018-01-15T19:34:55.470425: Epoch   0 Batch  500/3125   train_loss = 0.958\n",
      "2018-01-15T19:34:56.452481: Epoch   0 Batch  520/3125   train_loss = 1.244\n",
      "2018-01-15T19:34:57.453539: Epoch   0 Batch  540/3125   train_loss = 1.129\n",
      "2018-01-15T19:34:58.433595: Epoch   0 Batch  560/3125   train_loss = 1.308\n",
      "2018-01-15T19:34:59.379649: Epoch   0 Batch  580/3125   train_loss = 1.354\n",
      "2018-01-15T19:35:00.317702: Epoch   0 Batch  600/3125   train_loss = 1.301\n",
      "2018-01-15T19:35:01.349762: Epoch   0 Batch  620/3125   train_loss = 1.371\n",
      "2018-01-15T19:35:02.300816: Epoch   0 Batch  640/3125   train_loss = 1.290\n",
      "2018-01-15T19:35:03.242870: Epoch   0 Batch  660/3125   train_loss = 1.270\n",
      "2018-01-15T19:35:04.179923: Epoch   0 Batch  680/3125   train_loss = 1.130\n",
      "2018-01-15T19:35:05.212982: Epoch   0 Batch  700/3125   train_loss = 1.231\n",
      "2018-01-15T19:35:06.464054: Epoch   0 Batch  720/3125   train_loss = 1.188\n",
      "2018-01-15T19:35:07.514114: Epoch   0 Batch  740/3125   train_loss = 1.270\n",
      "2018-01-15T19:35:08.448168: Epoch   0 Batch  760/3125   train_loss = 1.313\n",
      "2018-01-15T19:35:09.624235: Epoch   0 Batch  780/3125   train_loss = 1.338\n",
      "2018-01-15T19:35:10.541287: Epoch   0 Batch  800/3125   train_loss = 1.201\n",
      "2018-01-15T19:35:11.464340: Epoch   0 Batch  820/3125   train_loss = 1.185\n",
      "2018-01-15T19:35:12.370392: Epoch   0 Batch  840/3125   train_loss = 1.124\n",
      "2018-01-15T19:35:13.295445: Epoch   0 Batch  860/3125   train_loss = 1.124\n",
      "2018-01-15T19:35:14.160494: Epoch   0 Batch  880/3125   train_loss = 1.168\n",
      "2018-01-15T19:35:15.079547: Epoch   0 Batch  900/3125   train_loss = 1.168\n",
      "2018-01-15T19:35:16.025601: Epoch   0 Batch  920/3125   train_loss = 1.220\n",
      "2018-01-15T19:35:16.998657: Epoch   0 Batch  940/3125   train_loss = 1.321\n",
      "2018-01-15T19:35:18.023715: Epoch   0 Batch  960/3125   train_loss = 1.283\n",
      "2018-01-15T19:35:19.075775: Epoch   0 Batch  980/3125   train_loss = 1.302\n",
      "2018-01-15T19:35:20.041831: Epoch   0 Batch 1000/3125   train_loss = 1.208\n",
      "2018-01-15T19:35:21.150894: Epoch   0 Batch 1020/3125   train_loss = 1.252\n",
      "2018-01-15T19:35:22.157952: Epoch   0 Batch 1040/3125   train_loss = 1.220\n",
      "2018-01-15T19:35:23.084005: Epoch   0 Batch 1060/3125   train_loss = 1.412\n",
      "2018-01-15T19:35:24.020058: Epoch   0 Batch 1080/3125   train_loss = 1.137\n",
      "2018-01-15T19:35:24.935111: Epoch   0 Batch 1100/3125   train_loss = 1.289\n",
      "2018-01-15T19:35:25.805160: Epoch   0 Batch 1120/3125   train_loss = 1.213\n",
      "2018-01-15T19:35:26.773216: Epoch   0 Batch 1140/3125   train_loss = 1.266\n",
      "2018-01-15T19:35:27.683268: Epoch   0 Batch 1160/3125   train_loss = 1.222\n",
      "2018-01-15T19:35:28.600320: Epoch   0 Batch 1180/3125   train_loss = 1.204\n",
      "2018-01-15T19:35:29.513372: Epoch   0 Batch 1200/3125   train_loss = 1.163\n",
      "2018-01-15T19:35:30.468427: Epoch   0 Batch 1220/3125   train_loss = 1.096\n",
      "2018-01-15T19:35:31.642494: Epoch   0 Batch 1240/3125   train_loss = 1.104\n",
      "2018-01-15T19:35:32.592549: Epoch   0 Batch 1260/3125   train_loss = 1.172\n",
      "2018-01-15T19:35:33.471599: Epoch   0 Batch 1280/3125   train_loss = 1.181\n",
      "2018-01-15T19:35:34.360650: Epoch   0 Batch 1300/3125   train_loss = 1.181\n",
      "2018-01-15T19:35:35.429711: Epoch   0 Batch 1320/3125   train_loss = 1.173\n",
      "2018-01-15T19:35:36.766787: Epoch   0 Batch 1340/3125   train_loss = 1.061\n",
      "2018-01-15T19:35:37.763844: Epoch   0 Batch 1360/3125   train_loss = 1.103\n",
      "2018-01-15T19:35:38.699898: Epoch   0 Batch 1380/3125   train_loss = 1.076\n",
      "2018-01-15T19:35:39.729957: Epoch   0 Batch 1400/3125   train_loss = 1.204\n",
      "2018-01-15T19:35:40.707013: Epoch   0 Batch 1420/3125   train_loss = 1.200\n",
      "2018-01-15T19:35:41.710070: Epoch   0 Batch 1440/3125   train_loss = 1.078\n",
      "2018-01-15T19:35:42.627122: Epoch   0 Batch 1460/3125   train_loss = 1.170\n",
      "2018-01-15T19:35:43.645181: Epoch   0 Batch 1480/3125   train_loss = 1.214\n",
      "2018-01-15T19:35:44.508230: Epoch   0 Batch 1500/3125   train_loss = 1.311\n",
      "2018-01-15T19:35:45.470285: Epoch   0 Batch 1520/3125   train_loss = 1.233\n",
      "2018-01-15T19:35:46.478343: Epoch   0 Batch 1540/3125   train_loss = 1.206\n",
      "2018-01-15T19:35:47.481400: Epoch   0 Batch 1560/3125   train_loss = 1.113\n",
      "2018-01-15T19:35:48.462456: Epoch   0 Batch 1580/3125   train_loss = 1.173\n",
      "2018-01-15T19:35:49.451513: Epoch   0 Batch 1600/3125   train_loss = 1.211\n",
      "2018-01-15T19:35:50.449570: Epoch   0 Batch 1620/3125   train_loss = 1.093\n",
      "2018-01-15T19:35:51.528632: Epoch   0 Batch 1640/3125   train_loss = 1.238\n",
      "2018-01-15T19:35:52.634695: Epoch   0 Batch 1660/3125   train_loss = 1.256\n",
      "2018-01-15T19:35:53.822763: Epoch   0 Batch 1680/3125   train_loss = 1.140\n",
      "2018-01-15T19:35:54.802819: Epoch   0 Batch 1700/3125   train_loss = 1.048\n",
      "2018-01-15T19:35:55.722871: Epoch   0 Batch 1720/3125   train_loss = 1.138\n",
      "2018-01-15T19:35:56.724929: Epoch   0 Batch 1740/3125   train_loss = 1.152\n",
      "2018-01-15T19:35:57.664983: Epoch   0 Batch 1760/3125   train_loss = 1.263\n",
      "2018-01-15T19:35:58.575035: Epoch   0 Batch 1780/3125   train_loss = 1.036\n",
      "2018-01-15T19:35:59.497087: Epoch   0 Batch 1800/3125   train_loss = 1.107\n",
      "2018-01-15T19:36:00.444142: Epoch   0 Batch 1820/3125   train_loss = 1.112\n",
      "2018-01-15T19:36:01.471200: Epoch   0 Batch 1840/3125   train_loss = 1.249\n",
      "2018-01-15T19:36:02.422255: Epoch   0 Batch 1860/3125   train_loss = 1.190\n",
      "2018-01-15T19:36:03.327306: Epoch   0 Batch 1880/3125   train_loss = 1.241\n",
      "2018-01-15T19:36:04.252359: Epoch   0 Batch 1900/3125   train_loss = 1.032\n",
      "2018-01-15T19:36:05.302419: Epoch   0 Batch 1920/3125   train_loss = 1.120\n",
      "2018-01-15T19:36:06.530490: Epoch   0 Batch 1940/3125   train_loss = 1.065\n",
      "2018-01-15T19:36:07.575549: Epoch   0 Batch 1960/3125   train_loss = 1.098\n",
      "2018-01-15T19:36:08.494602: Epoch   0 Batch 1980/3125   train_loss = 1.043\n",
      "2018-01-15T19:36:09.468658: Epoch   0 Batch 2000/3125   train_loss = 1.327\n",
      "2018-01-15T19:36:10.481716: Epoch   0 Batch 2020/3125   train_loss = 1.190\n",
      "2018-01-15T19:36:11.657783: Epoch   0 Batch 2040/3125   train_loss = 1.059\n",
      "2018-01-15T19:36:12.598837: Epoch   0 Batch 2060/3125   train_loss = 0.967\n",
      "2018-01-15T19:36:13.510889: Epoch   0 Batch 2080/3125   train_loss = 1.226\n",
      "2018-01-15T19:36:14.367938: Epoch   0 Batch 2100/3125   train_loss = 1.044\n",
      "2018-01-15T19:36:15.285990: Epoch   0 Batch 2120/3125   train_loss = 1.003\n",
      "2018-01-15T19:36:16.237045: Epoch   0 Batch 2140/3125   train_loss = 1.105\n",
      "2018-01-15T19:36:17.215101: Epoch   0 Batch 2160/3125   train_loss = 1.083\n",
      "2018-01-15T19:36:18.155155: Epoch   0 Batch 2180/3125   train_loss = 1.084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-15T19:36:19.070207: Epoch   0 Batch 2200/3125   train_loss = 1.040\n",
      "2018-01-15T19:36:19.966258: Epoch   0 Batch 2220/3125   train_loss = 1.086\n",
      "2018-01-15T19:36:21.123324: Epoch   0 Batch 2240/3125   train_loss = 0.981\n",
      "2018-01-15T19:36:22.206386: Epoch   0 Batch 2260/3125   train_loss = 1.061\n",
      "2018-01-15T19:36:23.215444: Epoch   0 Batch 2280/3125   train_loss = 1.119\n",
      "2018-01-15T19:36:24.370510: Epoch   0 Batch 2300/3125   train_loss = 1.130\n",
      "2018-01-15T19:36:25.329565: Epoch   0 Batch 2320/3125   train_loss = 1.216\n",
      "2018-01-15T19:36:26.357624: Epoch   0 Batch 2340/3125   train_loss = 1.111\n",
      "2018-01-15T19:36:27.360681: Epoch   0 Batch 2360/3125   train_loss = 1.063\n",
      "2018-01-15T19:36:28.288734: Epoch   0 Batch 2380/3125   train_loss = 1.102\n",
      "2018-01-15T19:36:29.279791: Epoch   0 Batch 2400/3125   train_loss = 1.167\n",
      "2018-01-15T19:36:30.189843: Epoch   0 Batch 2420/3125   train_loss = 1.055\n",
      "2018-01-15T19:36:31.177899: Epoch   0 Batch 2440/3125   train_loss = 1.141\n",
      "2018-01-15T19:36:32.205958: Epoch   0 Batch 2460/3125   train_loss = 1.030\n",
      "2018-01-15T19:36:33.134011: Epoch   0 Batch 2480/3125   train_loss = 1.094\n",
      "2018-01-15T19:36:34.023062: Epoch   0 Batch 2500/3125   train_loss = 1.137\n",
      "2018-01-15T19:36:34.922114: Epoch   0 Batch 2520/3125   train_loss = 1.017\n",
      "2018-01-15T19:36:36.092180: Epoch   0 Batch 2540/3125   train_loss = 1.035\n",
      "2018-01-15T19:36:37.303250: Epoch   0 Batch 2560/3125   train_loss = 0.922\n",
      "2018-01-15T19:36:38.185300: Epoch   0 Batch 2580/3125   train_loss = 1.071\n",
      "2018-01-15T19:36:39.128354: Epoch   0 Batch 2600/3125   train_loss = 1.040\n",
      "2018-01-15T19:36:40.017405: Epoch   0 Batch 2620/3125   train_loss = 0.983\n",
      "2018-01-15T19:36:41.118468: Epoch   0 Batch 2640/3125   train_loss = 1.062\n",
      "2018-01-15T19:36:42.416542: Epoch   0 Batch 2660/3125   train_loss = 1.105\n",
      "2018-01-15T19:36:43.372597: Epoch   0 Batch 2680/3125   train_loss = 0.967\n",
      "2018-01-15T19:36:44.263648: Epoch   0 Batch 2700/3125   train_loss = 1.144\n",
      "2018-01-15T19:36:45.137698: Epoch   0 Batch 2720/3125   train_loss = 1.096\n",
      "2018-01-15T19:36:46.026749: Epoch   0 Batch 2740/3125   train_loss = 1.118\n",
      "2018-01-15T19:36:47.009805: Epoch   0 Batch 2760/3125   train_loss = 1.095\n",
      "2018-01-15T19:36:47.915857: Epoch   0 Batch 2780/3125   train_loss = 1.016\n",
      "2018-01-15T19:36:48.812908: Epoch   0 Batch 2800/3125   train_loss = 1.333\n",
      "2018-01-15T19:36:49.726960: Epoch   0 Batch 2820/3125   train_loss = 1.314\n",
      "2018-01-15T19:36:50.654013: Epoch   0 Batch 2840/3125   train_loss = 1.008\n",
      "2018-01-15T19:36:51.654071: Epoch   0 Batch 2860/3125   train_loss = 1.085\n",
      "2018-01-15T19:36:52.691130: Epoch   0 Batch 2880/3125   train_loss = 1.093\n",
      "2018-01-15T19:36:53.915200: Epoch   0 Batch 2900/3125   train_loss = 1.080\n",
      "2018-01-15T19:36:54.952259: Epoch   0 Batch 2920/3125   train_loss = 1.110\n",
      "2018-01-15T19:36:55.865311: Epoch   0 Batch 2940/3125   train_loss = 1.056\n",
      "2018-01-15T19:36:56.923372: Epoch   0 Batch 2960/3125   train_loss = 1.034\n",
      "2018-01-15T19:36:57.856425: Epoch   0 Batch 2980/3125   train_loss = 1.026\n",
      "2018-01-15T19:36:58.765477: Epoch   0 Batch 3000/3125   train_loss = 1.067\n",
      "2018-01-15T19:36:59.689530: Epoch   0 Batch 3020/3125   train_loss = 1.198\n",
      "2018-01-15T19:37:00.626584: Epoch   0 Batch 3040/3125   train_loss = 1.093\n",
      "2018-01-15T19:37:01.540636: Epoch   0 Batch 3060/3125   train_loss = 1.035\n",
      "2018-01-15T19:37:02.493691: Epoch   0 Batch 3080/3125   train_loss = 1.197\n",
      "2018-01-15T19:37:03.440745: Epoch   0 Batch 3100/3125   train_loss = 1.166\n",
      "2018-01-15T19:37:04.313795: Epoch   0 Batch 3120/3125   train_loss = 0.948\n",
      "2018-01-15T19:37:04.722818: Epoch   0 Batch    0/781   test_loss = 0.997\n",
      "2018-01-15T19:37:05.186845: Epoch   0 Batch   20/781   test_loss = 1.056\n",
      "2018-01-15T19:37:05.680873: Epoch   0 Batch   40/781   test_loss = 0.948\n",
      "2018-01-15T19:37:06.225904: Epoch   0 Batch   60/781   test_loss = 1.239\n",
      "2018-01-15T19:37:06.736933: Epoch   0 Batch   80/781   test_loss = 1.185\n",
      "2018-01-15T19:37:07.163958: Epoch   0 Batch  100/781   test_loss = 1.176\n",
      "2018-01-15T19:37:07.562981: Epoch   0 Batch  120/781   test_loss = 1.074\n",
      "2018-01-15T19:37:07.941002: Epoch   0 Batch  140/781   test_loss = 1.080\n",
      "2018-01-15T19:37:08.347025: Epoch   0 Batch  160/781   test_loss = 1.159\n",
      "2018-01-15T19:37:08.734047: Epoch   0 Batch  180/781   test_loss = 1.068\n",
      "2018-01-15T19:37:09.199074: Epoch   0 Batch  200/781   test_loss = 1.059\n",
      "2018-01-15T19:37:09.559095: Epoch   0 Batch  220/781   test_loss = 0.868\n",
      "2018-01-15T19:37:09.923115: Epoch   0 Batch  240/781   test_loss = 1.067\n",
      "2018-01-15T19:37:10.367141: Epoch   0 Batch  260/781   test_loss = 1.087\n",
      "2018-01-15T19:37:10.773164: Epoch   0 Batch  280/781   test_loss = 1.253\n",
      "2018-01-15T19:37:11.173187: Epoch   0 Batch  300/781   test_loss = 1.027\n",
      "2018-01-15T19:37:11.631213: Epoch   0 Batch  320/781   test_loss = 1.161\n",
      "2018-01-15T19:37:12.169244: Epoch   0 Batch  340/781   test_loss = 0.829\n",
      "2018-01-15T19:37:12.664272: Epoch   0 Batch  360/781   test_loss = 1.120\n",
      "2018-01-15T19:37:13.092297: Epoch   0 Batch  380/781   test_loss = 1.022\n",
      "2018-01-15T19:37:13.603326: Epoch   0 Batch  400/781   test_loss = 0.995\n",
      "2018-01-15T19:37:13.984348: Epoch   0 Batch  420/781   test_loss = 0.974\n",
      "2018-01-15T19:37:14.356369: Epoch   0 Batch  440/781   test_loss = 1.174\n",
      "2018-01-15T19:37:14.728390: Epoch   0 Batch  460/781   test_loss = 1.002\n",
      "2018-01-15T19:37:15.113412: Epoch   0 Batch  480/781   test_loss = 0.989\n",
      "2018-01-15T19:37:15.482433: Epoch   0 Batch  500/781   test_loss = 0.890\n",
      "2018-01-15T19:37:15.857455: Epoch   0 Batch  520/781   test_loss = 1.045\n",
      "2018-01-15T19:37:16.325482: Epoch   0 Batch  540/781   test_loss = 0.920\n",
      "2018-01-15T19:37:16.689503: Epoch   0 Batch  560/781   test_loss = 1.112\n",
      "2018-01-15T19:37:17.099526: Epoch   0 Batch  580/781   test_loss = 1.040\n",
      "2018-01-15T19:37:17.508549: Epoch   0 Batch  600/781   test_loss = 1.119\n",
      "2018-01-15T19:37:17.864570: Epoch   0 Batch  620/781   test_loss = 1.060\n",
      "2018-01-15T19:37:18.294594: Epoch   0 Batch  640/781   test_loss = 1.175\n",
      "2018-01-15T19:37:18.658615: Epoch   0 Batch  660/781   test_loss = 1.072\n",
      "2018-01-15T19:37:19.078639: Epoch   0 Batch  680/781   test_loss = 1.220\n",
      "2018-01-15T19:37:19.480662: Epoch   0 Batch  700/781   test_loss = 1.054\n",
      "2018-01-15T19:37:19.819682: Epoch   0 Batch  720/781   test_loss = 1.171\n",
      "2018-01-15T19:37:20.213704: Epoch   0 Batch  740/781   test_loss = 1.075\n",
      "2018-01-15T19:37:20.674730: Epoch   0 Batch  760/781   test_loss = 1.100\n",
      "2018-01-15T19:37:21.054752: Epoch   0 Batch  780/781   test_loss = 1.093\n",
      "2018-01-15T19:37:22.720847: Epoch   1 Batch   15/3125   train_loss = 1.092\n",
      "2018-01-15T19:37:23.803909: Epoch   1 Batch   35/3125   train_loss = 1.036\n",
      "2018-01-15T19:37:24.783965: Epoch   1 Batch   55/3125   train_loss = 1.131\n",
      "2018-01-15T19:37:25.664016: Epoch   1 Batch   75/3125   train_loss = 1.064\n",
      "2018-01-15T19:37:26.672073: Epoch   1 Batch   95/3125   train_loss = 0.935\n",
      "2018-01-15T19:37:27.652130: Epoch   1 Batch  115/3125   train_loss = 1.210\n",
      "2018-01-15T19:37:28.541180: Epoch   1 Batch  135/3125   train_loss = 0.981\n",
      "2018-01-15T19:37:29.483234: Epoch   1 Batch  155/3125   train_loss = 1.042\n",
      "2018-01-15T19:37:30.379286: Epoch   1 Batch  175/3125   train_loss = 1.060\n",
      "2018-01-15T19:37:31.391343: Epoch   1 Batch  195/3125   train_loss = 1.133\n",
      "2018-01-15T19:37:32.270394: Epoch   1 Batch  215/3125   train_loss = 1.045\n",
      "2018-01-15T19:37:33.210447: Epoch   1 Batch  235/3125   train_loss = 1.022\n",
      "2018-01-15T19:37:34.089498: Epoch   1 Batch  255/3125   train_loss = 1.157\n",
      "2018-01-15T19:37:34.992549: Epoch   1 Batch  275/3125   train_loss = 0.947\n",
      "2018-01-15T19:37:36.169617: Epoch   1 Batch  295/3125   train_loss = 0.942\n",
      "2018-01-15T19:37:37.247678: Epoch   1 Batch  315/3125   train_loss = 1.047\n",
      "2018-01-15T19:37:38.210733: Epoch   1 Batch  335/3125   train_loss = 0.951\n",
      "2018-01-15T19:37:39.135786: Epoch   1 Batch  355/3125   train_loss = 1.037\n",
      "2018-01-15T19:37:40.012837: Epoch   1 Batch  375/3125   train_loss = 1.091\n",
      "2018-01-15T19:37:40.985892: Epoch   1 Batch  395/3125   train_loss = 0.992\n",
      "2018-01-15T19:37:41.891944: Epoch   1 Batch  415/3125   train_loss = 1.150\n",
      "2018-01-15T19:37:42.905002: Epoch   1 Batch  435/3125   train_loss = 1.095\n",
      "2018-01-15T19:37:43.861057: Epoch   1 Batch  455/3125   train_loss = 1.018\n",
      "2018-01-15T19:37:44.757108: Epoch   1 Batch  475/3125   train_loss = 1.038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-15T19:37:45.612157: Epoch   1 Batch  495/3125   train_loss = 0.985\n",
      "2018-01-15T19:37:46.532209: Epoch   1 Batch  515/3125   train_loss = 1.029\n",
      "2018-01-15T19:37:47.461263: Epoch   1 Batch  535/3125   train_loss = 1.085\n",
      "2018-01-15T19:37:48.370315: Epoch   1 Batch  555/3125   train_loss = 1.178\n",
      "2018-01-15T19:37:49.324369: Epoch   1 Batch  575/3125   train_loss = 1.083\n",
      "2018-01-15T19:37:50.172418: Epoch   1 Batch  595/3125   train_loss = 1.188\n",
      "2018-01-15T19:37:51.123472: Epoch   1 Batch  615/3125   train_loss = 1.052\n",
      "2018-01-15T19:37:52.051525: Epoch   1 Batch  635/3125   train_loss = 1.059\n",
      "2018-01-15T19:37:53.152588: Epoch   1 Batch  655/3125   train_loss = 0.889\n",
      "2018-01-15T19:37:54.411660: Epoch   1 Batch  675/3125   train_loss = 0.841\n",
      "2018-01-15T19:37:55.393716: Epoch   1 Batch  695/3125   train_loss = 0.969\n",
      "2018-01-15T19:37:56.382773: Epoch   1 Batch  715/3125   train_loss = 1.041\n",
      "2018-01-15T19:37:57.418832: Epoch   1 Batch  735/3125   train_loss = 0.930\n",
      "2018-01-15T19:37:58.361886: Epoch   1 Batch  755/3125   train_loss = 1.115\n",
      "2018-01-15T19:37:59.260937: Epoch   1 Batch  775/3125   train_loss = 0.925\n",
      "2018-01-15T19:38:00.131987: Epoch   1 Batch  795/3125   train_loss = 1.065\n",
      "2018-01-15T19:38:01.173047: Epoch   1 Batch  815/3125   train_loss = 0.961\n",
      "2018-01-15T19:38:02.034096: Epoch   1 Batch  835/3125   train_loss = 0.993\n",
      "2018-01-15T19:38:02.939148: Epoch   1 Batch  855/3125   train_loss = 1.240\n",
      "2018-01-15T19:38:03.894202: Epoch   1 Batch  875/3125   train_loss = 1.089\n",
      "2018-01-15T19:38:04.795254: Epoch   1 Batch  895/3125   train_loss = 0.932\n",
      "2018-01-15T19:38:05.897317: Epoch   1 Batch  915/3125   train_loss = 1.056\n",
      "2018-01-15T19:38:07.055383: Epoch   1 Batch  935/3125   train_loss = 1.091\n",
      "2018-01-15T19:38:07.922433: Epoch   1 Batch  955/3125   train_loss = 1.080\n",
      "2018-01-15T19:38:08.847486: Epoch   1 Batch  975/3125   train_loss = 1.056\n",
      "2018-01-15T19:38:09.805541: Epoch   1 Batch  995/3125   train_loss = 0.893\n",
      "2018-01-15T19:38:10.690591: Epoch   1 Batch 1015/3125   train_loss = 1.070\n",
      "2018-01-15T19:38:11.610644: Epoch   1 Batch 1035/3125   train_loss = 1.056\n",
      "2018-01-15T19:38:12.533697: Epoch   1 Batch 1055/3125   train_loss = 1.032\n",
      "2018-01-15T19:38:13.540754: Epoch   1 Batch 1075/3125   train_loss = 0.959\n",
      "2018-01-15T19:38:14.447806: Epoch   1 Batch 1095/3125   train_loss = 0.933\n",
      "2018-01-15T19:38:15.317856: Epoch   1 Batch 1115/3125   train_loss = 1.084\n",
      "2018-01-15T19:38:16.229908: Epoch   1 Batch 1135/3125   train_loss = 1.022\n",
      "2018-01-15T19:38:17.175962: Epoch   1 Batch 1155/3125   train_loss = 1.018\n",
      "2018-01-15T19:38:18.083014: Epoch   1 Batch 1175/3125   train_loss = 1.064\n",
      "2018-01-15T19:38:18.962064: Epoch   1 Batch 1195/3125   train_loss = 1.135\n",
      "2018-01-15T19:38:19.882117: Epoch   1 Batch 1215/3125   train_loss = 0.871\n",
      "2018-01-15T19:38:20.836171: Epoch   1 Batch 1235/3125   train_loss = 1.057\n",
      "2018-01-15T19:38:21.719222: Epoch   1 Batch 1255/3125   train_loss = 1.000\n",
      "2018-01-15T19:38:22.623274: Epoch   1 Batch 1275/3125   train_loss = 0.987\n",
      "2018-01-15T19:38:23.689335: Epoch   1 Batch 1295/3125   train_loss = 0.966\n",
      "2018-01-15T19:38:24.821399: Epoch   1 Batch 1315/3125   train_loss = 1.117\n",
      "2018-01-15T19:38:25.829457: Epoch   1 Batch 1335/3125   train_loss = 0.969\n",
      "2018-01-15T19:38:26.898518: Epoch   1 Batch 1355/3125   train_loss = 1.011\n",
      "2018-01-15T19:38:27.921577: Epoch   1 Batch 1375/3125   train_loss = 1.043\n",
      "2018-01-15T19:38:28.782626: Epoch   1 Batch 1395/3125   train_loss = 0.946\n",
      "2018-01-15T19:38:29.736681: Epoch   1 Batch 1415/3125   train_loss = 0.997\n",
      "2018-01-15T19:38:30.683735: Epoch   1 Batch 1435/3125   train_loss = 1.068\n",
      "2018-01-15T19:38:31.635789: Epoch   1 Batch 1455/3125   train_loss = 1.096\n",
      "2018-01-15T19:38:32.611845: Epoch   1 Batch 1475/3125   train_loss = 1.064\n",
      "2018-01-15T19:38:33.559899: Epoch   1 Batch 1495/3125   train_loss = 0.973\n",
      "2018-01-15T19:38:34.432949: Epoch   1 Batch 1515/3125   train_loss = 0.883\n",
      "2018-01-15T19:38:35.475009: Epoch   1 Batch 1535/3125   train_loss = 0.817\n",
      "2018-01-15T19:38:36.652076: Epoch   1 Batch 1555/3125   train_loss = 1.038\n",
      "2018-01-15T19:38:37.625132: Epoch   1 Batch 1575/3125   train_loss = 0.946\n",
      "2018-01-15T19:38:38.515183: Epoch   1 Batch 1595/3125   train_loss = 1.086\n",
      "2018-01-15T19:38:39.447236: Epoch   1 Batch 1615/3125   train_loss = 0.989\n",
      "2018-01-15T19:38:40.354288: Epoch   1 Batch 1635/3125   train_loss = 1.046\n",
      "2018-01-15T19:38:41.199336: Epoch   1 Batch 1655/3125   train_loss = 1.089\n",
      "2018-01-15T19:38:42.133390: Epoch   1 Batch 1675/3125   train_loss = 0.999\n",
      "2018-01-15T19:38:43.027441: Epoch   1 Batch 1695/3125   train_loss = 1.035\n",
      "2018-01-15T19:38:43.981495: Epoch   1 Batch 1715/3125   train_loss = 0.890\n",
      "2018-01-15T19:38:44.971552: Epoch   1 Batch 1735/3125   train_loss = 1.068\n",
      "2018-01-15T19:38:45.851602: Epoch   1 Batch 1755/3125   train_loss = 0.964\n",
      "2018-01-15T19:38:46.758654: Epoch   1 Batch 1775/3125   train_loss = 1.006\n",
      "2018-01-15T19:38:47.713709: Epoch   1 Batch 1795/3125   train_loss = 1.018\n",
      "2018-01-15T19:38:48.618761: Epoch   1 Batch 1815/3125   train_loss = 0.944\n",
      "2018-01-15T19:38:49.510812: Epoch   1 Batch 1835/3125   train_loss = 1.089\n",
      "2018-01-15T19:38:50.422864: Epoch   1 Batch 1855/3125   train_loss = 0.930\n",
      "2018-01-15T19:38:51.328916: Epoch   1 Batch 1875/3125   train_loss = 1.049\n",
      "2018-01-15T19:38:52.221967: Epoch   1 Batch 1895/3125   train_loss = 0.901\n",
      "2018-01-15T19:38:53.272027: Epoch   1 Batch 1915/3125   train_loss = 0.857\n",
      "2018-01-15T19:38:54.408092: Epoch   1 Batch 1935/3125   train_loss = 0.929\n",
      "2018-01-15T19:38:55.436150: Epoch   1 Batch 1955/3125   train_loss = 0.994\n",
      "2018-01-15T19:38:56.452209: Epoch   1 Batch 1975/3125   train_loss = 1.006\n",
      "2018-01-15T19:38:57.524270: Epoch   1 Batch 1995/3125   train_loss = 1.068\n",
      "2018-01-15T19:38:58.519327: Epoch   1 Batch 2015/3125   train_loss = 1.033\n",
      "2018-01-15T19:38:59.411378: Epoch   1 Batch 2035/3125   train_loss = 1.087\n",
      "2018-01-15T19:39:00.260426: Epoch   1 Batch 2055/3125   train_loss = 0.962\n",
      "2018-01-15T19:39:01.177479: Epoch   1 Batch 2075/3125   train_loss = 1.153\n",
      "2018-01-15T19:39:02.160535: Epoch   1 Batch 2095/3125   train_loss = 0.945\n",
      "2018-01-15T19:39:03.079588: Epoch   1 Batch 2115/3125   train_loss = 1.106\n",
      "2018-01-15T19:39:03.956638: Epoch   1 Batch 2135/3125   train_loss = 0.958\n",
      "2018-01-15T19:39:04.872690: Epoch   1 Batch 2155/3125   train_loss = 0.928\n",
      "2018-01-15T19:39:05.999755: Epoch   1 Batch 2175/3125   train_loss = 0.937\n",
      "2018-01-15T19:39:07.141820: Epoch   1 Batch 2195/3125   train_loss = 1.000\n",
      "2018-01-15T19:39:08.021870: Epoch   1 Batch 2215/3125   train_loss = 0.933\n",
      "2018-01-15T19:39:08.941923: Epoch   1 Batch 2235/3125   train_loss = 1.077\n",
      "2018-01-15T19:39:09.817973: Epoch   1 Batch 2255/3125   train_loss = 1.084\n",
      "2018-01-15T19:39:10.718025: Epoch   1 Batch 2275/3125   train_loss = 0.830\n",
      "2018-01-15T19:39:11.644078: Epoch   1 Batch 2295/3125   train_loss = 1.156\n",
      "2018-01-15T19:39:12.535128: Epoch   1 Batch 2315/3125   train_loss = 1.090\n",
      "2018-01-15T19:39:13.462182: Epoch   1 Batch 2335/3125   train_loss = 0.987\n",
      "2018-01-15T19:39:14.324231: Epoch   1 Batch 2355/3125   train_loss = 1.026\n",
      "2018-01-15T19:39:15.450295: Epoch   1 Batch 2375/3125   train_loss = 1.109\n",
      "2018-01-15T19:39:16.380348: Epoch   1 Batch 2395/3125   train_loss = 0.957\n",
      "2018-01-15T19:39:17.274400: Epoch   1 Batch 2415/3125   train_loss = 0.979\n",
      "2018-01-15T19:39:18.172451: Epoch   1 Batch 2435/3125   train_loss = 0.922\n",
      "2018-01-15T19:39:19.129506: Epoch   1 Batch 2455/3125   train_loss = 1.001\n",
      "2018-01-15T19:39:20.090561: Epoch   1 Batch 2475/3125   train_loss = 0.928\n",
      "2018-01-15T19:39:21.010613: Epoch   1 Batch 2495/3125   train_loss = 0.952\n",
      "2018-01-15T19:39:21.885663: Epoch   1 Batch 2515/3125   train_loss = 1.013\n",
      "2018-01-15T19:39:22.795715: Epoch   1 Batch 2535/3125   train_loss = 1.054\n",
      "2018-01-15T19:39:23.813774: Epoch   1 Batch 2555/3125   train_loss = 0.855\n",
      "2018-01-15T19:39:24.875834: Epoch   1 Batch 2575/3125   train_loss = 0.889\n",
      "2018-01-15T19:39:25.813888: Epoch   1 Batch 2595/3125   train_loss = 0.932\n",
      "2018-01-15T19:39:26.900950: Epoch   1 Batch 2615/3125   train_loss = 1.094\n",
      "2018-01-15T19:39:27.977012: Epoch   1 Batch 2635/3125   train_loss = 0.908\n",
      "2018-01-15T19:39:29.019071: Epoch   1 Batch 2655/3125   train_loss = 0.979\n",
      "2018-01-15T19:39:29.927123: Epoch   1 Batch 2675/3125   train_loss = 0.889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-15T19:39:30.844176: Epoch   1 Batch 2695/3125   train_loss = 0.963\n",
      "2018-01-15T19:39:31.719226: Epoch   1 Batch 2715/3125   train_loss = 0.954\n",
      "2018-01-15T19:39:32.608277: Epoch   1 Batch 2735/3125   train_loss = 0.847\n",
      "2018-01-15T19:39:33.594333: Epoch   1 Batch 2755/3125   train_loss = 1.075\n",
      "2018-01-15T19:39:34.480384: Epoch   1 Batch 2775/3125   train_loss = 0.985\n",
      "2018-01-15T19:39:35.496442: Epoch   1 Batch 2795/3125   train_loss = 1.020\n",
      "2018-01-15T19:39:36.618506: Epoch   1 Batch 2815/3125   train_loss = 0.920\n",
      "2018-01-15T19:39:37.618563: Epoch   1 Batch 2835/3125   train_loss = 1.028\n",
      "2018-01-15T19:39:38.555617: Epoch   1 Batch 2855/3125   train_loss = 0.995\n",
      "2018-01-15T19:39:39.458668: Epoch   1 Batch 2875/3125   train_loss = 0.937\n",
      "2018-01-15T19:39:40.343719: Epoch   1 Batch 2895/3125   train_loss = 0.942\n",
      "2018-01-15T19:39:41.221769: Epoch   1 Batch 2915/3125   train_loss = 0.885\n",
      "2018-01-15T19:39:42.133821: Epoch   1 Batch 2935/3125   train_loss = 1.086\n",
      "2018-01-15T19:39:43.055874: Epoch   1 Batch 2955/3125   train_loss = 0.941\n",
      "2018-01-15T19:39:44.004928: Epoch   1 Batch 2975/3125   train_loss = 0.849\n",
      "2018-01-15T19:39:44.931981: Epoch   1 Batch 2995/3125   train_loss = 0.836\n",
      "2018-01-15T19:39:45.864035: Epoch   1 Batch 3015/3125   train_loss = 0.989\n",
      "2018-01-15T19:39:46.890093: Epoch   1 Batch 3035/3125   train_loss = 0.944\n",
      "2018-01-15T19:39:47.837148: Epoch   1 Batch 3055/3125   train_loss = 1.022\n",
      "2018-01-15T19:39:48.768201: Epoch   1 Batch 3075/3125   train_loss = 0.885\n",
      "2018-01-15T19:39:49.631250: Epoch   1 Batch 3095/3125   train_loss = 0.863\n",
      "2018-01-15T19:39:50.501300: Epoch   1 Batch 3115/3125   train_loss = 0.846\n",
      "2018-01-15T19:39:52.150394: Epoch   1 Batch   19/781   test_loss = 1.000\n",
      "2018-01-15T19:39:52.838434: Epoch   1 Batch   39/781   test_loss = 0.794\n",
      "2018-01-15T19:39:53.471470: Epoch   1 Batch   59/781   test_loss = 0.904\n",
      "2018-01-15T19:39:54.032502: Epoch   1 Batch   79/781   test_loss = 0.988\n",
      "2018-01-15T19:39:54.452526: Epoch   1 Batch   99/781   test_loss = 0.940\n",
      "2018-01-15T19:39:54.893551: Epoch   1 Batch  119/781   test_loss = 0.918\n",
      "2018-01-15T19:39:55.299574: Epoch   1 Batch  139/781   test_loss = 0.996\n",
      "2018-01-15T19:39:55.716598: Epoch   1 Batch  159/781   test_loss = 0.985\n",
      "2018-01-15T19:39:56.196626: Epoch   1 Batch  179/781   test_loss = 0.878\n",
      "2018-01-15T19:39:56.684654: Epoch   1 Batch  199/781   test_loss = 0.890\n",
      "2018-01-15T19:39:57.250686: Epoch   1 Batch  219/781   test_loss = 0.962\n",
      "2018-01-15T19:39:57.725713: Epoch   1 Batch  239/781   test_loss = 1.196\n",
      "2018-01-15T19:39:58.114736: Epoch   1 Batch  259/781   test_loss = 0.992\n",
      "2018-01-15T19:39:58.604764: Epoch   1 Batch  279/781   test_loss = 1.036\n",
      "2018-01-15T19:39:58.957784: Epoch   1 Batch  299/781   test_loss = 1.114\n",
      "2018-01-15T19:39:59.355806: Epoch   1 Batch  319/781   test_loss = 0.906\n",
      "2018-01-15T19:39:59.774830: Epoch   1 Batch  339/781   test_loss = 0.880\n",
      "2018-01-15T19:40:00.180854: Epoch   1 Batch  359/781   test_loss = 0.898\n",
      "2018-01-15T19:40:00.559875: Epoch   1 Batch  379/781   test_loss = 0.991\n",
      "2018-01-15T19:40:00.986900: Epoch   1 Batch  399/781   test_loss = 0.829\n",
      "2018-01-15T19:40:01.359921: Epoch   1 Batch  419/781   test_loss = 0.964\n",
      "2018-01-15T19:40:01.736943: Epoch   1 Batch  439/781   test_loss = 0.941\n",
      "2018-01-15T19:40:02.176968: Epoch   1 Batch  459/781   test_loss = 1.007\n",
      "2018-01-15T19:40:02.534988: Epoch   1 Batch  479/781   test_loss = 0.989\n",
      "2018-01-15T19:40:02.898009: Epoch   1 Batch  499/781   test_loss = 0.894\n",
      "2018-01-15T19:40:03.325034: Epoch   1 Batch  519/781   test_loss = 0.988\n",
      "2018-01-15T19:40:03.748058: Epoch   1 Batch  539/781   test_loss = 0.825\n",
      "2018-01-15T19:40:04.131080: Epoch   1 Batch  559/781   test_loss = 1.083\n",
      "2018-01-15T19:40:04.530102: Epoch   1 Batch  579/781   test_loss = 1.012\n",
      "2018-01-15T19:40:04.913124: Epoch   1 Batch  599/781   test_loss = 0.900\n",
      "2018-01-15T19:40:05.439154: Epoch   1 Batch  619/781   test_loss = 1.069\n",
      "2018-01-15T19:40:05.864179: Epoch   1 Batch  639/781   test_loss = 0.828\n",
      "2018-01-15T19:40:06.357207: Epoch   1 Batch  659/781   test_loss = 1.043\n",
      "2018-01-15T19:40:06.878237: Epoch   1 Batch  679/781   test_loss = 1.091\n",
      "2018-01-15T19:40:07.245258: Epoch   1 Batch  699/781   test_loss = 0.803\n",
      "2018-01-15T19:40:07.640280: Epoch   1 Batch  719/781   test_loss = 0.953\n",
      "2018-01-15T19:40:08.031303: Epoch   1 Batch  739/781   test_loss = 0.934\n",
      "2018-01-15T19:40:08.468328: Epoch   1 Batch  759/781   test_loss = 0.868\n",
      "2018-01-15T19:40:08.874351: Epoch   1 Batch  779/781   test_loss = 0.761\n",
      "2018-01-15T19:40:10.158424: Epoch   2 Batch   10/3125   train_loss = 0.902\n",
      "2018-01-15T19:40:11.172482: Epoch   2 Batch   30/3125   train_loss = 0.991\n",
      "2018-01-15T19:40:12.182540: Epoch   2 Batch   50/3125   train_loss = 1.048\n",
      "2018-01-15T19:40:13.188598: Epoch   2 Batch   70/3125   train_loss = 0.953\n",
      "2018-01-15T19:40:14.241658: Epoch   2 Batch   90/3125   train_loss = 1.001\n",
      "2018-01-15T19:40:15.273717: Epoch   2 Batch  110/3125   train_loss = 0.861\n",
      "2018-01-15T19:40:16.263774: Epoch   2 Batch  130/3125   train_loss = 0.911\n",
      "2018-01-15T19:40:17.276832: Epoch   2 Batch  150/3125   train_loss = 0.993\n",
      "2018-01-15T19:40:18.341892: Epoch   2 Batch  170/3125   train_loss = 0.993\n",
      "2018-01-15T19:40:19.339950: Epoch   2 Batch  190/3125   train_loss = 0.914\n",
      "2018-01-15T19:40:20.325006: Epoch   2 Batch  210/3125   train_loss = 0.917\n",
      "2018-01-15T19:40:21.334064: Epoch   2 Batch  230/3125   train_loss = 1.063\n",
      "2018-01-15T19:40:22.350122: Epoch   2 Batch  250/3125   train_loss = 0.865\n",
      "2018-01-15T19:40:23.493187: Epoch   2 Batch  270/3125   train_loss = 0.734\n",
      "2018-01-15T19:40:24.606251: Epoch   2 Batch  290/3125   train_loss = 1.056\n",
      "2018-01-15T19:40:25.624309: Epoch   2 Batch  310/3125   train_loss = 0.975\n",
      "2018-01-15T19:40:26.751373: Epoch   2 Batch  330/3125   train_loss = 1.017\n",
      "2018-01-15T19:40:27.945442: Epoch   2 Batch  350/3125   train_loss = 0.868\n",
      "2018-01-15T19:40:29.131510: Epoch   2 Batch  370/3125   train_loss = 1.105\n",
      "2018-01-15T19:40:30.179570: Epoch   2 Batch  390/3125   train_loss = 1.067\n",
      "2018-01-15T19:40:31.305634: Epoch   2 Batch  410/3125   train_loss = 0.886\n",
      "2018-01-15T19:40:32.299691: Epoch   2 Batch  430/3125   train_loss = 1.090\n",
      "2018-01-15T19:40:33.276747: Epoch   2 Batch  450/3125   train_loss = 0.868\n",
      "2018-01-15T19:40:34.343808: Epoch   2 Batch  470/3125   train_loss = 0.879\n",
      "2018-01-15T19:40:35.602880: Epoch   2 Batch  490/3125   train_loss = 0.969\n",
      "2018-01-15T19:40:36.930956: Epoch   2 Batch  510/3125   train_loss = 1.069\n",
      "2018-01-15T19:40:37.992016: Epoch   2 Batch  530/3125   train_loss = 0.886\n",
      "2018-01-15T19:40:38.989073: Epoch   2 Batch  550/3125   train_loss = 0.989\n",
      "2018-01-15T19:40:39.964129: Epoch   2 Batch  570/3125   train_loss = 0.996\n",
      "2018-01-15T19:40:40.994188: Epoch   2 Batch  590/3125   train_loss = 1.024\n",
      "2018-01-15T19:40:41.980244: Epoch   2 Batch  610/3125   train_loss = 0.834\n",
      "2018-01-15T19:40:42.980302: Epoch   2 Batch  630/3125   train_loss = 1.028\n",
      "2018-01-15T19:40:44.061363: Epoch   2 Batch  650/3125   train_loss = 0.926\n",
      "2018-01-15T19:40:45.053420: Epoch   2 Batch  670/3125   train_loss = 0.946\n",
      "2018-01-15T19:40:46.010475: Epoch   2 Batch  690/3125   train_loss = 0.888\n",
      "2018-01-15T19:40:47.091537: Epoch   2 Batch  710/3125   train_loss = 0.957\n",
      "2018-01-15T19:40:48.244603: Epoch   2 Batch  730/3125   train_loss = 0.784\n",
      "2018-01-15T19:40:49.296663: Epoch   2 Batch  750/3125   train_loss = 0.923\n",
      "2018-01-15T19:40:50.301720: Epoch   2 Batch  770/3125   train_loss = 0.867\n",
      "2018-01-15T19:40:51.310778: Epoch   2 Batch  790/3125   train_loss = 0.827\n",
      "2018-01-15T19:40:52.306835: Epoch   2 Batch  810/3125   train_loss = 0.839\n",
      "2018-01-15T19:40:53.450901: Epoch   2 Batch  830/3125   train_loss = 0.829\n",
      "2018-01-15T19:40:54.669970: Epoch   2 Batch  850/3125   train_loss = 0.953\n",
      "2018-01-15T19:40:55.716030: Epoch   2 Batch  870/3125   train_loss = 0.855\n",
      "2018-01-15T19:40:56.749089: Epoch   2 Batch  890/3125   train_loss = 0.837\n",
      "2018-01-15T19:40:57.920156: Epoch   2 Batch  910/3125   train_loss = 0.965\n",
      "2018-01-15T19:40:59.024219: Epoch   2 Batch  930/3125   train_loss = 0.950\n",
      "2018-01-15T19:41:00.118282: Epoch   2 Batch  950/3125   train_loss = 0.895\n",
      "2018-01-15T19:41:01.202344: Epoch   2 Batch  970/3125   train_loss = 0.964\n",
      "2018-01-15T19:41:02.237403: Epoch   2 Batch  990/3125   train_loss = 0.808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-15T19:41:03.236460: Epoch   2 Batch 1010/3125   train_loss = 1.077\n",
      "2018-01-15T19:41:04.417528: Epoch   2 Batch 1030/3125   train_loss = 0.894\n",
      "2018-01-15T19:41:05.694601: Epoch   2 Batch 1050/3125   train_loss = 0.884\n",
      "2018-01-15T19:41:07.132683: Epoch   2 Batch 1070/3125   train_loss = 0.884\n",
      "2018-01-15T19:41:08.216745: Epoch   2 Batch 1090/3125   train_loss = 1.021\n",
      "2018-01-15T19:41:09.209802: Epoch   2 Batch 1110/3125   train_loss = 1.020\n",
      "2018-01-15T19:41:10.228860: Epoch   2 Batch 1130/3125   train_loss = 0.905\n",
      "2018-01-15T19:41:11.257919: Epoch   2 Batch 1150/3125   train_loss = 0.957\n",
      "2018-01-15T19:41:12.303979: Epoch   2 Batch 1170/3125   train_loss = 0.954\n",
      "2018-01-15T19:41:13.330038: Epoch   2 Batch 1190/3125   train_loss = 0.963\n",
      "2018-01-15T19:41:14.333095: Epoch   2 Batch 1210/3125   train_loss = 0.831\n",
      "2018-01-15T19:41:15.587167: Epoch   2 Batch 1230/3125   train_loss = 0.786\n",
      "2018-01-15T19:41:16.655228: Epoch   2 Batch 1250/3125   train_loss = 0.963\n",
      "2018-01-15T19:41:17.783292: Epoch   2 Batch 1270/3125   train_loss = 0.883\n",
      "2018-01-15T19:41:18.888355: Epoch   2 Batch 1290/3125   train_loss = 0.863\n",
      "2018-01-15T19:41:19.866411: Epoch   2 Batch 1310/3125   train_loss = 0.880\n",
      "2018-01-15T19:41:20.869469: Epoch   2 Batch 1330/3125   train_loss = 1.019\n",
      "2018-01-15T19:41:21.821523: Epoch   2 Batch 1350/3125   train_loss = 0.861\n",
      "2018-01-15T19:41:22.820580: Epoch   2 Batch 1370/3125   train_loss = 0.797\n",
      "2018-01-15T19:41:23.830638: Epoch   2 Batch 1390/3125   train_loss = 0.955\n",
      "2018-01-15T19:41:24.902699: Epoch   2 Batch 1410/3125   train_loss = 0.867\n",
      "2018-01-15T19:41:25.867755: Epoch   2 Batch 1430/3125   train_loss = 0.910\n",
      "2018-01-15T19:41:26.901814: Epoch   2 Batch 1450/3125   train_loss = 0.928\n",
      "2018-01-15T19:41:27.930873: Epoch   2 Batch 1470/3125   train_loss = 0.926\n",
      "2018-01-15T19:41:28.964932: Epoch   2 Batch 1490/3125   train_loss = 0.944\n",
      "2018-01-15T19:41:30.067995: Epoch   2 Batch 1510/3125   train_loss = 0.919\n",
      "2018-01-15T19:41:31.190059: Epoch   2 Batch 1530/3125   train_loss = 1.040\n",
      "2018-01-15T19:41:32.307123: Epoch   2 Batch 1550/3125   train_loss = 0.859\n",
      "2018-01-15T19:41:33.293179: Epoch   2 Batch 1570/3125   train_loss = 0.932\n",
      "2018-01-15T19:41:34.246234: Epoch   2 Batch 1590/3125   train_loss = 0.920\n",
      "2018-01-15T19:41:35.357297: Epoch   2 Batch 1610/3125   train_loss = 0.825\n",
      "2018-01-15T19:41:36.709375: Epoch   2 Batch 1630/3125   train_loss = 0.974\n",
      "2018-01-15T19:41:37.824439: Epoch   2 Batch 1650/3125   train_loss = 0.794\n",
      "2018-01-15T19:41:38.785494: Epoch   2 Batch 1670/3125   train_loss = 0.790\n",
      "2018-01-15T19:41:39.746549: Epoch   2 Batch 1690/3125   train_loss = 0.915\n",
      "2018-01-15T19:41:40.725605: Epoch   2 Batch 1710/3125   train_loss = 0.936\n",
      "2018-01-15T19:41:41.709661: Epoch   2 Batch 1730/3125   train_loss = 0.969\n",
      "2018-01-15T19:41:42.708718: Epoch   2 Batch 1750/3125   train_loss = 0.797\n",
      "2018-01-15T19:41:43.660772: Epoch   2 Batch 1770/3125   train_loss = 1.091\n",
      "2018-01-15T19:41:44.615827: Epoch   2 Batch 1790/3125   train_loss = 0.932\n",
      "2018-01-15T19:41:45.799895: Epoch   2 Batch 1810/3125   train_loss = 0.988\n",
      "2018-01-15T19:41:46.813953: Epoch   2 Batch 1830/3125   train_loss = 0.999\n",
      "2018-01-15T19:41:47.911015: Epoch   2 Batch 1850/3125   train_loss = 0.874\n",
      "2018-01-15T19:41:48.915073: Epoch   2 Batch 1870/3125   train_loss = 0.987\n",
      "2018-01-15T19:41:49.888129: Epoch   2 Batch 1890/3125   train_loss = 0.774\n",
      "2018-01-15T19:41:50.859184: Epoch   2 Batch 1910/3125   train_loss = 0.848\n",
      "2018-01-15T19:41:51.829240: Epoch   2 Batch 1930/3125   train_loss = 1.005\n",
      "2018-01-15T19:41:52.856298: Epoch   2 Batch 1950/3125   train_loss = 0.837\n",
      "2018-01-15T19:41:53.857356: Epoch   2 Batch 1970/3125   train_loss = 0.927\n",
      "2018-01-15T19:41:54.906416: Epoch   2 Batch 1990/3125   train_loss = 0.863\n",
      "2018-01-15T19:41:55.752464: Epoch   2 Batch 2010/3125   train_loss = 0.795\n",
      "2018-01-15T19:41:56.656516: Epoch   2 Batch 2030/3125   train_loss = 0.887\n",
      "2018-01-15T19:41:57.562568: Epoch   2 Batch 2050/3125   train_loss = 0.939\n",
      "2018-01-15T19:41:58.412616: Epoch   2 Batch 2070/3125   train_loss = 0.886\n",
      "2018-01-15T19:41:59.250664: Epoch   2 Batch 2090/3125   train_loss = 0.808\n",
      "2018-01-15T19:42:00.236720: Epoch   2 Batch 2110/3125   train_loss = 0.929\n",
      "2018-01-15T19:42:01.242778: Epoch   2 Batch 2130/3125   train_loss = 0.883\n",
      "2018-01-15T19:42:02.195833: Epoch   2 Batch 2150/3125   train_loss = 0.952\n",
      "2018-01-15T19:42:03.104885: Epoch   2 Batch 2170/3125   train_loss = 0.855\n",
      "2018-01-15T19:42:03.943933: Epoch   2 Batch 2190/3125   train_loss = 0.960\n",
      "2018-01-15T19:42:04.798981: Epoch   2 Batch 2210/3125   train_loss = 0.915\n",
      "2018-01-15T19:42:05.876043: Epoch   2 Batch 2230/3125   train_loss = 0.803\n",
      "2018-01-15T19:42:06.984106: Epoch   2 Batch 2250/3125   train_loss = 0.961\n",
      "2018-01-15T19:42:07.839155: Epoch   2 Batch 2270/3125   train_loss = 0.888\n",
      "2018-01-15T19:42:08.680203: Epoch   2 Batch 2290/3125   train_loss = 0.818\n",
      "2018-01-15T19:42:09.529252: Epoch   2 Batch 2310/3125   train_loss = 0.826\n",
      "2018-01-15T19:42:10.385301: Epoch   2 Batch 2330/3125   train_loss = 1.032\n",
      "2018-01-15T19:42:11.213348: Epoch   2 Batch 2350/3125   train_loss = 0.968\n",
      "2018-01-15T19:42:12.076398: Epoch   2 Batch 2370/3125   train_loss = 0.932\n",
      "2018-01-15T19:42:12.968449: Epoch   2 Batch 2390/3125   train_loss = 0.991\n",
      "2018-01-15T19:42:13.834498: Epoch   2 Batch 2410/3125   train_loss = 1.033\n",
      "2018-01-15T19:42:14.675546: Epoch   2 Batch 2430/3125   train_loss = 0.887\n",
      "2018-01-15T19:42:15.530595: Epoch   2 Batch 2450/3125   train_loss = 0.967\n",
      "2018-01-15T19:42:16.715663: Epoch   2 Batch 2470/3125   train_loss = 1.053\n",
      "2018-01-15T19:42:17.694719: Epoch   2 Batch 2490/3125   train_loss = 0.986\n",
      "2018-01-15T19:42:18.593770: Epoch   2 Batch 2510/3125   train_loss = 0.989\n",
      "2018-01-15T19:42:19.480821: Epoch   2 Batch 2530/3125   train_loss = 0.789\n",
      "2018-01-15T19:42:20.356871: Epoch   2 Batch 2550/3125   train_loss = 0.977\n",
      "2018-01-15T19:42:21.241922: Epoch   2 Batch 2570/3125   train_loss = 0.957\n",
      "2018-01-15T19:42:22.065969: Epoch   2 Batch 2590/3125   train_loss = 0.915\n",
      "2018-01-15T19:42:22.981021: Epoch   2 Batch 2610/3125   train_loss = 0.975\n",
      "2018-01-15T19:42:23.911075: Epoch   2 Batch 2630/3125   train_loss = 0.661\n",
      "2018-01-15T19:42:24.830127: Epoch   2 Batch 2650/3125   train_loss = 0.864\n",
      "2018-01-15T19:42:25.708177: Epoch   2 Batch 2670/3125   train_loss = 0.936\n",
      "2018-01-15T19:42:26.734236: Epoch   2 Batch 2690/3125   train_loss = 0.940\n",
      "2018-01-15T19:42:27.700291: Epoch   2 Batch 2710/3125   train_loss = 0.816\n",
      "2018-01-15T19:42:28.586342: Epoch   2 Batch 2730/3125   train_loss = 1.043\n",
      "2018-01-15T19:42:29.449391: Epoch   2 Batch 2750/3125   train_loss = 1.005\n",
      "2018-01-15T19:42:30.451449: Epoch   2 Batch 2770/3125   train_loss = 0.888\n",
      "2018-01-15T19:42:31.406503: Epoch   2 Batch 2790/3125   train_loss = 0.876\n",
      "2018-01-15T19:42:32.440562: Epoch   2 Batch 2810/3125   train_loss = 0.884\n",
      "2018-01-15T19:42:33.384616: Epoch   2 Batch 2830/3125   train_loss = 0.813\n",
      "2018-01-15T19:42:34.237665: Epoch   2 Batch 2850/3125   train_loss = 0.943\n",
      "2018-01-15T19:42:35.209721: Epoch   2 Batch 2870/3125   train_loss = 0.769\n",
      "2018-01-15T19:42:36.326785: Epoch   2 Batch 2890/3125   train_loss = 0.771\n",
      "2018-01-15T19:42:37.363844: Epoch   2 Batch 2910/3125   train_loss = 0.932\n",
      "2018-01-15T19:42:38.235894: Epoch   2 Batch 2930/3125   train_loss = 0.711\n",
      "2018-01-15T19:42:39.063941: Epoch   2 Batch 2950/3125   train_loss = 0.962\n",
      "2018-01-15T19:42:39.924991: Epoch   2 Batch 2970/3125   train_loss = 0.928\n",
      "2018-01-15T19:42:40.796040: Epoch   2 Batch 2990/3125   train_loss = 0.846\n",
      "2018-01-15T19:42:41.652089: Epoch   2 Batch 3010/3125   train_loss = 0.922\n",
      "2018-01-15T19:42:42.539140: Epoch   2 Batch 3030/3125   train_loss = 0.904\n",
      "2018-01-15T19:42:43.397189: Epoch   2 Batch 3050/3125   train_loss = 0.879\n",
      "2018-01-15T19:42:44.246238: Epoch   2 Batch 3070/3125   train_loss = 0.813\n",
      "2018-01-15T19:42:45.103287: Epoch   2 Batch 3090/3125   train_loss = 0.742\n",
      "2018-01-15T19:42:45.965336: Epoch   2 Batch 3110/3125   train_loss = 0.832\n",
      "2018-01-15T19:42:47.221408: Epoch   2 Batch   18/781   test_loss = 0.769\n",
      "2018-01-15T19:42:47.766439: Epoch   2 Batch   38/781   test_loss = 0.872\n",
      "2018-01-15T19:42:48.203464: Epoch   2 Batch   58/781   test_loss = 0.809\n",
      "2018-01-15T19:42:48.580486: Epoch   2 Batch   78/781   test_loss = 0.838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-15T19:42:48.989509: Epoch   2 Batch   98/781   test_loss = 0.896\n",
      "2018-01-15T19:42:49.350530: Epoch   2 Batch  118/781   test_loss = 0.852\n",
      "2018-01-15T19:42:49.743552: Epoch   2 Batch  138/781   test_loss = 1.010\n",
      "2018-01-15T19:42:50.155576: Epoch   2 Batch  158/781   test_loss = 0.814\n",
      "2018-01-15T19:42:50.529597: Epoch   2 Batch  178/781   test_loss = 0.841\n",
      "2018-01-15T19:42:50.996624: Epoch   2 Batch  198/781   test_loss = 0.893\n",
      "2018-01-15T19:42:51.459650: Epoch   2 Batch  218/781   test_loss = 0.970\n",
      "2018-01-15T19:42:51.901676: Epoch   2 Batch  238/781   test_loss = 0.896\n",
      "2018-01-15T19:42:52.329700: Epoch   2 Batch  258/781   test_loss = 0.996\n",
      "2018-01-15T19:42:52.708722: Epoch   2 Batch  278/781   test_loss = 1.014\n",
      "2018-01-15T19:42:53.077743: Epoch   2 Batch  298/781   test_loss = 0.851\n",
      "2018-01-15T19:42:53.483766: Epoch   2 Batch  318/781   test_loss = 0.867\n",
      "2018-01-15T19:42:53.884789: Epoch   2 Batch  338/781   test_loss = 0.897\n",
      "2018-01-15T19:42:54.286812: Epoch   2 Batch  358/781   test_loss = 0.958\n",
      "2018-01-15T19:42:54.732837: Epoch   2 Batch  378/781   test_loss = 0.800\n",
      "2018-01-15T19:42:55.099858: Epoch   2 Batch  398/781   test_loss = 0.776\n",
      "2018-01-15T19:42:55.516882: Epoch   2 Batch  418/781   test_loss = 0.940\n",
      "2018-01-15T19:42:55.934906: Epoch   2 Batch  438/781   test_loss = 0.957\n",
      "2018-01-15T19:42:56.352930: Epoch   2 Batch  458/781   test_loss = 0.876\n",
      "2018-01-15T19:42:56.764954: Epoch   2 Batch  478/781   test_loss = 0.877\n",
      "2018-01-15T19:42:57.170977: Epoch   2 Batch  498/781   test_loss = 0.748\n",
      "2018-01-15T19:42:57.552999: Epoch   2 Batch  518/781   test_loss = 0.848\n",
      "2018-01-15T19:42:57.968023: Epoch   2 Batch  538/781   test_loss = 0.822\n",
      "2018-01-15T19:42:58.370046: Epoch   2 Batch  558/781   test_loss = 0.828\n",
      "2018-01-15T19:42:58.754067: Epoch   2 Batch  578/781   test_loss = 0.878\n",
      "2018-01-15T19:42:59.191092: Epoch   2 Batch  598/781   test_loss = 0.984\n",
      "2018-01-15T19:42:59.584115: Epoch   2 Batch  618/781   test_loss = 0.843\n",
      "2018-01-15T19:42:59.974137: Epoch   2 Batch  638/781   test_loss = 0.842\n",
      "2018-01-15T19:43:00.410162: Epoch   2 Batch  658/781   test_loss = 0.984\n",
      "2018-01-15T19:43:00.862188: Epoch   2 Batch  678/781   test_loss = 0.926\n",
      "2018-01-15T19:43:01.350216: Epoch   2 Batch  698/781   test_loss = 0.875\n",
      "2018-01-15T19:43:01.821243: Epoch   2 Batch  718/781   test_loss = 0.948\n",
      "2018-01-15T19:43:02.306271: Epoch   2 Batch  738/781   test_loss = 0.822\n",
      "2018-01-15T19:43:02.801299: Epoch   2 Batch  758/781   test_loss = 0.921\n",
      "2018-01-15T19:43:03.246324: Epoch   2 Batch  778/781   test_loss = 0.860\n",
      "2018-01-15T19:43:04.419392: Epoch   3 Batch    5/3125   train_loss = 0.892\n",
      "2018-01-15T19:43:05.936478: Epoch   3 Batch   25/3125   train_loss = 0.891\n",
      "2018-01-15T19:43:07.805585: Epoch   3 Batch   45/3125   train_loss = 0.780\n",
      "2018-01-15T19:43:09.518683: Epoch   3 Batch   65/3125   train_loss = 0.964\n",
      "2018-01-15T19:43:10.763754: Epoch   3 Batch   85/3125   train_loss = 0.806\n",
      "2018-01-15T19:43:12.137833: Epoch   3 Batch  105/3125   train_loss = 0.695\n",
      "2018-01-15T19:43:13.577915: Epoch   3 Batch  125/3125   train_loss = 0.839\n",
      "2018-01-15T19:43:15.379018: Epoch   3 Batch  145/3125   train_loss = 0.850\n",
      "2018-01-15T19:43:17.526141: Epoch   3 Batch  165/3125   train_loss = 0.882\n",
      "2018-01-15T19:43:18.977224: Epoch   3 Batch  185/3125   train_loss = 0.790\n",
      "2018-01-15T19:43:20.254297: Epoch   3 Batch  205/3125   train_loss = 0.782\n",
      "2018-01-15T19:43:21.503369: Epoch   3 Batch  225/3125   train_loss = 0.748\n",
      "2018-01-15T19:43:22.609432: Epoch   3 Batch  245/3125   train_loss = 1.021\n",
      "2018-01-15T19:43:23.740497: Epoch   3 Batch  265/3125   train_loss = 0.842\n",
      "2018-01-15T19:43:25.212581: Epoch   3 Batch  285/3125   train_loss = 0.904\n",
      "2018-01-15T19:43:26.432651: Epoch   3 Batch  305/3125   train_loss = 0.777\n",
      "2018-01-15T19:43:27.268698: Epoch   3 Batch  325/3125   train_loss = 0.897\n",
      "2018-01-15T19:43:28.143748: Epoch   3 Batch  345/3125   train_loss = 0.989\n",
      "2018-01-15T19:43:29.026799: Epoch   3 Batch  365/3125   train_loss = 0.859\n",
      "2018-01-15T19:43:29.877848: Epoch   3 Batch  385/3125   train_loss = 0.815\n",
      "2018-01-15T19:43:30.741897: Epoch   3 Batch  405/3125   train_loss = 0.886\n",
      "2018-01-15T19:43:31.635948: Epoch   3 Batch  425/3125   train_loss = 0.916\n",
      "2018-01-15T19:43:32.632005: Epoch   3 Batch  445/3125   train_loss = 0.916\n",
      "2018-01-15T19:43:33.747069: Epoch   3 Batch  465/3125   train_loss = 0.836\n",
      "2018-01-15T19:43:35.224153: Epoch   3 Batch  485/3125   train_loss = 1.002\n",
      "2018-01-15T19:43:36.865247: Epoch   3 Batch  505/3125   train_loss = 0.802\n",
      "2018-01-15T19:43:37.889306: Epoch   3 Batch  525/3125   train_loss = 0.914\n",
      "2018-01-15T19:43:38.813359: Epoch   3 Batch  545/3125   train_loss = 0.822\n",
      "2018-01-15T19:43:39.820416: Epoch   3 Batch  565/3125   train_loss = 1.024\n",
      "2018-01-15T19:43:40.713467: Epoch   3 Batch  585/3125   train_loss = 0.820\n",
      "2018-01-15T19:43:41.613519: Epoch   3 Batch  605/3125   train_loss = 0.942\n",
      "2018-01-15T19:43:42.578574: Epoch   3 Batch  625/3125   train_loss = 0.842\n",
      "2018-01-15T19:43:43.592632: Epoch   3 Batch  645/3125   train_loss = 0.959\n",
      "2018-01-15T19:43:44.740698: Epoch   3 Batch  665/3125   train_loss = 0.948\n",
      "2018-01-15T19:43:45.777757: Epoch   3 Batch  685/3125   train_loss = 0.892\n",
      "2018-01-15T19:43:46.759813: Epoch   3 Batch  705/3125   train_loss = 1.077\n",
      "2018-01-15T19:43:47.679866: Epoch   3 Batch  725/3125   train_loss = 0.929\n",
      "2018-01-15T19:43:48.647921: Epoch   3 Batch  745/3125   train_loss = 0.860\n",
      "2018-01-15T19:43:49.508970: Epoch   3 Batch  765/3125   train_loss = 0.845\n",
      "2018-01-15T19:43:50.367020: Epoch   3 Batch  785/3125   train_loss = 1.040\n",
      "2018-01-15T19:43:51.215068: Epoch   3 Batch  805/3125   train_loss = 0.750\n",
      "2018-01-15T19:43:52.224126: Epoch   3 Batch  825/3125   train_loss = 0.869\n",
      "2018-01-15T19:43:53.240184: Epoch   3 Batch  845/3125   train_loss = 0.875\n",
      "2018-01-15T19:43:54.693267: Epoch   3 Batch  865/3125   train_loss = 0.942\n",
      "2018-01-15T19:43:56.345362: Epoch   3 Batch  885/3125   train_loss = 0.924\n",
      "2018-01-15T19:43:57.347419: Epoch   3 Batch  905/3125   train_loss = 1.006\n",
      "2018-01-15T19:43:58.352476: Epoch   3 Batch  925/3125   train_loss = 0.839\n",
      "2018-01-15T19:43:59.331532: Epoch   3 Batch  945/3125   train_loss = 0.892\n",
      "2018-01-15T19:44:00.304588: Epoch   3 Batch  965/3125   train_loss = 0.774\n",
      "2018-01-15T19:44:01.293645: Epoch   3 Batch  985/3125   train_loss = 0.950\n",
      "2018-01-15T19:44:02.438710: Epoch   3 Batch 1005/3125   train_loss = 0.682\n",
      "2018-01-15T19:44:03.632778: Epoch   3 Batch 1025/3125   train_loss = 0.869\n",
      "2018-01-15T19:44:05.358877: Epoch   3 Batch 1045/3125   train_loss = 1.077\n",
      "2018-01-15T19:44:07.063975: Epoch   3 Batch 1065/3125   train_loss = 0.879\n",
      "2018-01-15T19:44:08.482056: Epoch   3 Batch 1085/3125   train_loss = 0.754\n",
      "2018-01-15T19:44:09.592119: Epoch   3 Batch 1105/3125   train_loss = 0.809\n",
      "2018-01-15T19:44:10.717184: Epoch   3 Batch 1125/3125   train_loss = 0.850\n",
      "2018-01-15T19:44:11.881250: Epoch   3 Batch 1145/3125   train_loss = 0.837\n",
      "2018-01-15T19:44:13.016315: Epoch   3 Batch 1165/3125   train_loss = 0.960\n",
      "2018-01-15T19:44:14.450397: Epoch   3 Batch 1185/3125   train_loss = 0.821\n",
      "2018-01-15T19:44:15.653466: Epoch   3 Batch 1205/3125   train_loss = 0.839\n",
      "2018-01-15T19:44:16.766530: Epoch   3 Batch 1225/3125   train_loss = 0.882\n",
      "2018-01-15T19:44:17.782588: Epoch   3 Batch 1245/3125   train_loss = 0.979\n",
      "2018-01-15T19:44:18.839648: Epoch   3 Batch 1265/3125   train_loss = 0.932\n",
      "2018-01-15T19:44:19.840705: Epoch   3 Batch 1285/3125   train_loss = 0.961\n",
      "2018-01-15T19:44:20.849763: Epoch   3 Batch 1305/3125   train_loss = 0.774\n",
      "2018-01-15T19:44:21.890823: Epoch   3 Batch 1325/3125   train_loss = 0.806\n",
      "2018-01-15T19:44:22.996886: Epoch   3 Batch 1345/3125   train_loss = 0.907\n",
      "2018-01-15T19:44:24.175953: Epoch   3 Batch 1365/3125   train_loss = 0.759\n",
      "2018-01-15T19:44:25.640037: Epoch   3 Batch 1385/3125   train_loss = 0.772\n",
      "2018-01-15T19:44:26.778102: Epoch   3 Batch 1405/3125   train_loss = 0.900\n",
      "2018-01-15T19:44:27.780159: Epoch   3 Batch 1425/3125   train_loss = 1.043\n",
      "2018-01-15T19:44:28.777217: Epoch   3 Batch 1445/3125   train_loss = 0.933\n",
      "2018-01-15T19:44:29.788274: Epoch   3 Batch 1465/3125   train_loss = 0.875\n",
      "2018-01-15T19:44:30.813333: Epoch   3 Batch 1485/3125   train_loss = 0.940\n",
      "2018-01-15T19:44:31.875394: Epoch   3 Batch 1505/3125   train_loss = 0.716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-15T19:44:33.095464: Epoch   3 Batch 1525/3125   train_loss = 0.792\n",
      "2018-01-15T19:44:34.561547: Epoch   3 Batch 1545/3125   train_loss = 0.860\n",
      "2018-01-15T19:44:36.400653: Epoch   3 Batch 1565/3125   train_loss = 0.961\n",
      "2018-01-15T19:44:37.891738: Epoch   3 Batch 1585/3125   train_loss = 0.797\n",
      "2018-01-15T19:44:39.052804: Epoch   3 Batch 1605/3125   train_loss = 0.866\n",
      "2018-01-15T19:44:40.137866: Epoch   3 Batch 1625/3125   train_loss = 0.940\n",
      "2018-01-15T19:44:41.244930: Epoch   3 Batch 1645/3125   train_loss = 0.937\n",
      "2018-01-15T19:44:42.318991: Epoch   3 Batch 1665/3125   train_loss = 0.901\n",
      "2018-01-15T19:44:43.377052: Epoch   3 Batch 1685/3125   train_loss = 0.947\n",
      "2018-01-15T19:44:44.763131: Epoch   3 Batch 1705/3125   train_loss = 0.909\n",
      "2018-01-15T19:44:46.293218: Epoch   3 Batch 1725/3125   train_loss = 0.833\n",
      "2018-01-15T19:44:47.590293: Epoch   3 Batch 1745/3125   train_loss = 0.754\n",
      "2018-01-15T19:44:48.689355: Epoch   3 Batch 1765/3125   train_loss = 0.840\n",
      "2018-01-15T19:44:49.715414: Epoch   3 Batch 1785/3125   train_loss = 0.983\n",
      "2018-01-15T19:44:50.717471: Epoch   3 Batch 1805/3125   train_loss = 0.968\n",
      "2018-01-15T19:44:51.685527: Epoch   3 Batch 1825/3125   train_loss = 1.020\n",
      "2018-01-15T19:44:52.738587: Epoch   3 Batch 1845/3125   train_loss = 0.876\n",
      "2018-01-15T19:44:53.818649: Epoch   3 Batch 1865/3125   train_loss = 0.755\n",
      "2018-01-15T19:44:54.992716: Epoch   3 Batch 1885/3125   train_loss = 0.932\n",
      "2018-01-15T19:44:56.317792: Epoch   3 Batch 1905/3125   train_loss = 0.808\n",
      "2018-01-15T19:44:57.353851: Epoch   3 Batch 1925/3125   train_loss = 0.822\n",
      "2018-01-15T19:44:58.322906: Epoch   3 Batch 1945/3125   train_loss = 0.885\n",
      "2018-01-15T19:44:59.298962: Epoch   3 Batch 1965/3125   train_loss = 0.815\n",
      "2018-01-15T19:45:00.270018: Epoch   3 Batch 1985/3125   train_loss = 0.852\n",
      "2018-01-15T19:45:01.238073: Epoch   3 Batch 2005/3125   train_loss = 0.887\n",
      "2018-01-15T19:45:02.225130: Epoch   3 Batch 2025/3125   train_loss = 0.872\n",
      "2018-01-15T19:45:03.273190: Epoch   3 Batch 2045/3125   train_loss = 0.731\n",
      "2018-01-15T19:45:04.686270: Epoch   3 Batch 2065/3125   train_loss = 0.710\n",
      "2018-01-15T19:45:06.478373: Epoch   3 Batch 2085/3125   train_loss = 0.926\n",
      "2018-01-15T19:45:07.708443: Epoch   3 Batch 2105/3125   train_loss = 0.805\n",
      "2018-01-15T19:45:08.799506: Epoch   3 Batch 2125/3125   train_loss = 0.978\n",
      "2018-01-15T19:45:09.889568: Epoch   3 Batch 2145/3125   train_loss = 0.952\n",
      "2018-01-15T19:45:10.921627: Epoch   3 Batch 2165/3125   train_loss = 0.789\n",
      "2018-01-15T19:45:11.913684: Epoch   3 Batch 2185/3125   train_loss = 0.964\n",
      "2018-01-15T19:45:12.878739: Epoch   3 Batch 2205/3125   train_loss = 0.894\n",
      "2018-01-15T19:45:13.979802: Epoch   3 Batch 2225/3125   train_loss = 0.806\n",
      "2018-01-15T19:45:15.364881: Epoch   3 Batch 2245/3125   train_loss = 0.801\n",
      "2018-01-15T19:45:16.855966: Epoch   3 Batch 2265/3125   train_loss = 0.859\n",
      "2018-01-15T19:45:18.205044: Epoch   3 Batch 2285/3125   train_loss = 1.040\n",
      "2018-01-15T19:45:19.208101: Epoch   3 Batch 2305/3125   train_loss = 0.748\n",
      "2018-01-15T19:45:20.220159: Epoch   3 Batch 2325/3125   train_loss = 0.796\n",
      "2018-01-15T19:45:21.239217: Epoch   3 Batch 2345/3125   train_loss = 0.851\n",
      "2018-01-15T19:45:22.319279: Epoch   3 Batch 2365/3125   train_loss = 0.722\n",
      "2018-01-15T19:45:23.369339: Epoch   3 Batch 2385/3125   train_loss = 0.919\n",
      "2018-01-15T19:45:24.699415: Epoch   3 Batch 2405/3125   train_loss = 0.929\n",
      "2018-01-15T19:45:25.934486: Epoch   3 Batch 2425/3125   train_loss = 0.785\n",
      "2018-01-15T19:45:27.040549: Epoch   3 Batch 2445/3125   train_loss = 0.922\n",
      "2018-01-15T19:45:27.987603: Epoch   3 Batch 2465/3125   train_loss = 0.738\n",
      "2018-01-15T19:45:28.988660: Epoch   3 Batch 2485/3125   train_loss = 0.843\n",
      "2018-01-15T19:45:29.991718: Epoch   3 Batch 2505/3125   train_loss = 0.840\n",
      "2018-01-15T19:45:30.993775: Epoch   3 Batch 2525/3125   train_loss = 0.806\n",
      "2018-01-15T19:45:31.980832: Epoch   3 Batch 2545/3125   train_loss = 0.958\n",
      "2018-01-15T19:45:33.013891: Epoch   3 Batch 2565/3125   train_loss = 0.845\n",
      "2018-01-15T19:45:34.206959: Epoch   3 Batch 2585/3125   train_loss = 0.812\n",
      "2018-01-15T19:45:35.923057: Epoch   3 Batch 2605/3125   train_loss = 0.809\n",
      "2018-01-15T19:45:37.413142: Epoch   3 Batch 2625/3125   train_loss = 0.951\n",
      "2018-01-15T19:45:38.508205: Epoch   3 Batch 2645/3125   train_loss = 0.819\n",
      "2018-01-15T19:45:39.590267: Epoch   3 Batch 2665/3125   train_loss = 0.893\n",
      "2018-01-15T19:45:40.668328: Epoch   3 Batch 2685/3125   train_loss = 0.920\n",
      "2018-01-15T19:45:41.610382: Epoch   3 Batch 2705/3125   train_loss = 0.819\n",
      "2018-01-15T19:45:42.631441: Epoch   3 Batch 2725/3125   train_loss = 0.872\n",
      "2018-01-15T19:45:43.688501: Epoch   3 Batch 2745/3125   train_loss = 0.846\n",
      "2018-01-15T19:45:44.830567: Epoch   3 Batch 2765/3125   train_loss = 0.834\n",
      "2018-01-15T19:45:46.166643: Epoch   3 Batch 2785/3125   train_loss = 0.947\n",
      "2018-01-15T19:45:47.479718: Epoch   3 Batch 2805/3125   train_loss = 0.830\n",
      "2018-01-15T19:45:48.781793: Epoch   3 Batch 2825/3125   train_loss = 0.847\n",
      "2018-01-15T19:45:49.726847: Epoch   3 Batch 2845/3125   train_loss = 0.854\n",
      "2018-01-15T19:45:50.683901: Epoch   3 Batch 2865/3125   train_loss = 0.861\n",
      "2018-01-15T19:45:51.668958: Epoch   3 Batch 2885/3125   train_loss = 0.878\n",
      "2018-01-15T19:45:52.698017: Epoch   3 Batch 2905/3125   train_loss = 0.931\n",
      "2018-01-15T19:45:53.734076: Epoch   3 Batch 2925/3125   train_loss = 0.876\n",
      "2018-01-15T19:45:54.887142: Epoch   3 Batch 2945/3125   train_loss = 0.881\n",
      "2018-01-15T19:45:56.164215: Epoch   3 Batch 2965/3125   train_loss = 0.956\n",
      "2018-01-15T19:45:57.222275: Epoch   3 Batch 2985/3125   train_loss = 0.843\n",
      "2018-01-15T19:45:58.187330: Epoch   3 Batch 3005/3125   train_loss = 0.778\n",
      "2018-01-15T19:45:59.188388: Epoch   3 Batch 3025/3125   train_loss = 0.928\n",
      "2018-01-15T19:46:00.164444: Epoch   3 Batch 3045/3125   train_loss = 0.885\n",
      "2018-01-15T19:46:01.166501: Epoch   3 Batch 3065/3125   train_loss = 0.782\n",
      "2018-01-15T19:46:02.129556: Epoch   3 Batch 3085/3125   train_loss = 0.844\n",
      "2018-01-15T19:46:03.085611: Epoch   3 Batch 3105/3125   train_loss = 0.847\n",
      "2018-01-15T19:46:04.731705: Epoch   3 Batch   17/781   test_loss = 0.895\n",
      "2018-01-15T19:46:05.251735: Epoch   3 Batch   37/781   test_loss = 0.858\n",
      "2018-01-15T19:46:05.925773: Epoch   3 Batch   57/781   test_loss = 0.915\n",
      "2018-01-15T19:46:06.422802: Epoch   3 Batch   77/781   test_loss = 0.881\n",
      "2018-01-15T19:46:06.922830: Epoch   3 Batch   97/781   test_loss = 0.753\n",
      "2018-01-15T19:46:07.377856: Epoch   3 Batch  117/781   test_loss = 0.930\n",
      "2018-01-15T19:46:07.802880: Epoch   3 Batch  137/781   test_loss = 0.914\n",
      "2018-01-15T19:46:08.271907: Epoch   3 Batch  157/781   test_loss = 0.912\n",
      "2018-01-15T19:46:08.684931: Epoch   3 Batch  177/781   test_loss = 0.844\n",
      "2018-01-15T19:46:09.105955: Epoch   3 Batch  197/781   test_loss = 0.854\n",
      "2018-01-15T19:46:09.581982: Epoch   3 Batch  217/781   test_loss = 0.715\n",
      "2018-01-15T19:46:09.956004: Epoch   3 Batch  237/781   test_loss = 0.733\n",
      "2018-01-15T19:46:10.345026: Epoch   3 Batch  257/781   test_loss = 0.973\n",
      "2018-01-15T19:46:10.737048: Epoch   3 Batch  277/781   test_loss = 0.941\n",
      "2018-01-15T19:46:11.085068: Epoch   3 Batch  297/781   test_loss = 0.954\n",
      "2018-01-15T19:46:11.478091: Epoch   3 Batch  317/781   test_loss = 0.969\n",
      "2018-01-15T19:46:11.867113: Epoch   3 Batch  337/781   test_loss = 0.891\n",
      "2018-01-15T19:46:12.233134: Epoch   3 Batch  357/781   test_loss = 0.898\n",
      "2018-01-15T19:46:12.681159: Epoch   3 Batch  377/781   test_loss = 0.921\n",
      "2018-01-15T19:46:13.037180: Epoch   3 Batch  397/781   test_loss = 0.958\n",
      "2018-01-15T19:46:13.427202: Epoch   3 Batch  417/781   test_loss = 0.823\n",
      "2018-01-15T19:46:13.907230: Epoch   3 Batch  437/781   test_loss = 0.794\n",
      "2018-01-15T19:46:14.336254: Epoch   3 Batch  457/781   test_loss = 0.740\n",
      "2018-01-15T19:46:14.683274: Epoch   3 Batch  477/781   test_loss = 0.857\n",
      "2018-01-15T19:46:15.150301: Epoch   3 Batch  497/781   test_loss = 0.800\n",
      "2018-01-15T19:46:15.622328: Epoch   3 Batch  517/781   test_loss = 0.827\n",
      "2018-01-15T19:46:16.069353: Epoch   3 Batch  537/781   test_loss = 0.836\n",
      "2018-01-15T19:46:16.510378: Epoch   3 Batch  557/781   test_loss = 0.973\n",
      "2018-01-15T19:46:17.032408: Epoch   3 Batch  577/781   test_loss = 0.900\n",
      "2018-01-15T19:46:17.544438: Epoch   3 Batch  597/781   test_loss = 0.839\n",
      "2018-01-15T19:46:18.023465: Epoch   3 Batch  617/781   test_loss = 0.898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-15T19:46:18.535494: Epoch   3 Batch  637/781   test_loss = 0.815\n",
      "2018-01-15T19:46:18.888515: Epoch   3 Batch  657/781   test_loss = 0.988\n",
      "2018-01-15T19:46:19.274537: Epoch   3 Batch  677/781   test_loss = 0.912\n",
      "2018-01-15T19:46:19.676560: Epoch   3 Batch  697/781   test_loss = 0.902\n",
      "2018-01-15T19:46:20.034580: Epoch   3 Batch  717/781   test_loss = 0.822\n",
      "2018-01-15T19:46:20.406601: Epoch   3 Batch  737/781   test_loss = 0.754\n",
      "2018-01-15T19:46:20.803624: Epoch   3 Batch  757/781   test_loss = 1.002\n",
      "2018-01-15T19:46:21.170645: Epoch   3 Batch  777/781   test_loss = 0.909\n",
      "2018-01-15T19:46:21.940689: Epoch   4 Batch    0/3125   train_loss = 0.936\n",
      "2018-01-15T19:46:22.827740: Epoch   4 Batch   20/3125   train_loss = 0.842\n",
      "2018-01-15T19:46:23.747792: Epoch   4 Batch   40/3125   train_loss = 0.857\n",
      "2018-01-15T19:46:24.796852: Epoch   4 Batch   60/3125   train_loss = 0.756\n",
      "2018-01-15T19:46:25.881915: Epoch   4 Batch   80/3125   train_loss = 0.855\n",
      "2018-01-15T19:46:26.814968: Epoch   4 Batch  100/3125   train_loss = 0.935\n",
      "2018-01-15T19:46:27.724020: Epoch   4 Batch  120/3125   train_loss = 0.960\n",
      "2018-01-15T19:46:28.595070: Epoch   4 Batch  140/3125   train_loss = 0.907\n",
      "2018-01-15T19:46:29.473120: Epoch   4 Batch  160/3125   train_loss = 0.757\n",
      "2018-01-15T19:46:30.325169: Epoch   4 Batch  180/3125   train_loss = 0.800\n",
      "2018-01-15T19:46:31.174217: Epoch   4 Batch  200/3125   train_loss = 1.024\n",
      "2018-01-15T19:46:32.077269: Epoch   4 Batch  220/3125   train_loss = 0.828\n",
      "2018-01-15T19:46:32.971320: Epoch   4 Batch  240/3125   train_loss = 0.957\n",
      "2018-01-15T19:46:33.990378: Epoch   4 Batch  260/3125   train_loss = 0.933\n",
      "2018-01-15T19:46:35.050439: Epoch   4 Batch  280/3125   train_loss = 0.934\n",
      "2018-01-15T19:46:36.529524: Epoch   4 Batch  300/3125   train_loss = 1.020\n",
      "2018-01-15T19:46:37.600585: Epoch   4 Batch  320/3125   train_loss = 0.978\n",
      "2018-01-15T19:46:38.573640: Epoch   4 Batch  340/3125   train_loss = 0.693\n",
      "2018-01-15T19:46:39.546696: Epoch   4 Batch  360/3125   train_loss = 0.821\n",
      "2018-01-15T19:46:40.501751: Epoch   4 Batch  380/3125   train_loss = 0.834\n",
      "2018-01-15T19:46:41.459806: Epoch   4 Batch  400/3125   train_loss = 0.834\n",
      "2018-01-15T19:46:42.371858: Epoch   4 Batch  420/3125   train_loss = 0.747\n",
      "2018-01-15T19:46:43.250908: Epoch   4 Batch  440/3125   train_loss = 0.804\n",
      "2018-01-15T19:46:44.258966: Epoch   4 Batch  460/3125   train_loss = 0.836\n",
      "2018-01-15T19:46:45.199019: Epoch   4 Batch  480/3125   train_loss = 0.989\n",
      "2018-01-15T19:46:46.244079: Epoch   4 Batch  500/3125   train_loss = 0.676\n",
      "2018-01-15T19:46:47.191133: Epoch   4 Batch  520/3125   train_loss = 0.872\n",
      "2018-01-15T19:46:48.514209: Epoch   4 Batch  540/3125   train_loss = 0.797\n",
      "2018-01-15T19:46:49.545268: Epoch   4 Batch  560/3125   train_loss = 0.969\n",
      "2018-01-15T19:46:50.467321: Epoch   4 Batch  580/3125   train_loss = 0.958\n",
      "2018-01-15T19:46:51.270367: Epoch   4 Batch  600/3125   train_loss = 0.863\n",
      "2018-01-15T19:46:52.155417: Epoch   4 Batch  620/3125   train_loss = 0.866\n",
      "2018-01-15T19:46:53.061469: Epoch   4 Batch  640/3125   train_loss = 0.775\n",
      "2018-01-15T19:46:53.993522: Epoch   4 Batch  660/3125   train_loss = 0.850\n",
      "2018-01-15T19:46:54.866572: Epoch   4 Batch  680/3125   train_loss = 0.942\n",
      "2018-01-15T19:46:55.974636: Epoch   4 Batch  700/3125   train_loss = 0.916\n",
      "2018-01-15T19:46:56.926690: Epoch   4 Batch  720/3125   train_loss = 0.779\n",
      "2018-01-15T19:46:57.870744: Epoch   4 Batch  740/3125   train_loss = 0.912\n",
      "2018-01-15T19:46:58.739794: Epoch   4 Batch  760/3125   train_loss = 0.779\n",
      "2018-01-15T19:46:59.601843: Epoch   4 Batch  780/3125   train_loss = 0.875\n",
      "2018-01-15T19:47:00.480893: Epoch   4 Batch  800/3125   train_loss = 0.771\n",
      "2018-01-15T19:47:01.357944: Epoch   4 Batch  820/3125   train_loss = 0.840\n",
      "2018-01-15T19:47:02.178991: Epoch   4 Batch  840/3125   train_loss = 0.834\n",
      "2018-01-15T19:47:03.084042: Epoch   4 Batch  860/3125   train_loss = 0.783\n",
      "2018-01-15T19:47:04.152103: Epoch   4 Batch  880/3125   train_loss = 0.807\n",
      "2018-01-15T19:47:05.249166: Epoch   4 Batch  900/3125   train_loss = 0.828\n",
      "2018-01-15T19:47:06.622245: Epoch   4 Batch  920/3125   train_loss = 0.834\n",
      "2018-01-15T19:47:07.620302: Epoch   4 Batch  940/3125   train_loss = 0.846\n",
      "2018-01-15T19:47:08.512353: Epoch   4 Batch  960/3125   train_loss = 0.911\n",
      "2018-01-15T19:47:09.466407: Epoch   4 Batch  980/3125   train_loss = 0.968\n",
      "2018-01-15T19:47:10.429462: Epoch   4 Batch 1000/3125   train_loss = 0.919\n",
      "2018-01-15T19:47:11.380517: Epoch   4 Batch 1020/3125   train_loss = 0.864\n",
      "2018-01-15T19:47:12.343572: Epoch   4 Batch 1040/3125   train_loss = 0.725\n",
      "2018-01-15T19:47:13.191620: Epoch   4 Batch 1060/3125   train_loss = 0.912\n",
      "2018-01-15T19:47:14.161676: Epoch   4 Batch 1080/3125   train_loss = 0.875\n",
      "2018-01-15T19:47:15.084729: Epoch   4 Batch 1100/3125   train_loss = 0.865\n",
      "2018-01-15T19:47:16.164791: Epoch   4 Batch 1120/3125   train_loss = 0.873\n",
      "2018-01-15T19:47:17.107844: Epoch   4 Batch 1140/3125   train_loss = 0.877\n",
      "2018-01-15T19:47:18.247910: Epoch   4 Batch 1160/3125   train_loss = 0.760\n",
      "2018-01-15T19:47:19.354973: Epoch   4 Batch 1180/3125   train_loss = 0.848\n",
      "2018-01-15T19:47:20.411033: Epoch   4 Batch 1200/3125   train_loss = 0.949\n",
      "2018-01-15T19:47:21.306085: Epoch   4 Batch 1220/3125   train_loss = 0.894\n",
      "2018-01-15T19:47:22.210136: Epoch   4 Batch 1240/3125   train_loss = 0.766\n",
      "2018-01-15T19:47:23.159191: Epoch   4 Batch 1260/3125   train_loss = 0.810\n",
      "2018-01-15T19:47:24.089244: Epoch   4 Batch 1280/3125   train_loss = 0.889\n",
      "2018-01-15T19:47:25.077300: Epoch   4 Batch 1300/3125   train_loss = 0.769\n",
      "2018-01-15T19:47:26.124360: Epoch   4 Batch 1320/3125   train_loss = 0.857\n",
      "2018-01-15T19:47:27.078415: Epoch   4 Batch 1340/3125   train_loss = 0.735\n",
      "2018-01-15T19:47:28.007468: Epoch   4 Batch 1360/3125   train_loss = 0.774\n",
      "2018-01-15T19:47:28.858517: Epoch   4 Batch 1380/3125   train_loss = 0.841\n",
      "2018-01-15T19:47:29.751568: Epoch   4 Batch 1400/3125   train_loss = 0.899\n",
      "2018-01-15T19:47:30.607617: Epoch   4 Batch 1420/3125   train_loss = 0.873\n",
      "2018-01-15T19:47:31.457665: Epoch   4 Batch 1440/3125   train_loss = 0.751\n",
      "2018-01-15T19:47:32.343716: Epoch   4 Batch 1460/3125   train_loss = 0.853\n",
      "2018-01-15T19:47:33.243767: Epoch   4 Batch 1480/3125   train_loss = 0.789\n",
      "2018-01-15T19:47:34.292827: Epoch   4 Batch 1500/3125   train_loss = 0.901\n",
      "2018-01-15T19:47:35.379890: Epoch   4 Batch 1520/3125   train_loss = 0.812\n",
      "2018-01-15T19:47:36.710966: Epoch   4 Batch 1540/3125   train_loss = 0.920\n",
      "2018-01-15T19:47:37.668020: Epoch   4 Batch 1560/3125   train_loss = 0.752\n",
      "2018-01-15T19:47:38.578072: Epoch   4 Batch 1580/3125   train_loss = 0.926\n",
      "2018-01-15T19:47:39.662135: Epoch   4 Batch 1600/3125   train_loss = 0.789\n",
      "2018-01-15T19:47:40.764198: Epoch   4 Batch 1620/3125   train_loss = 0.776\n",
      "2018-01-15T19:47:41.840259: Epoch   4 Batch 1640/3125   train_loss = 0.898\n",
      "2018-01-15T19:47:42.915321: Epoch   4 Batch 1660/3125   train_loss = 0.954\n",
      "2018-01-15T19:47:44.063386: Epoch   4 Batch 1680/3125   train_loss = 0.837\n",
      "2018-01-15T19:47:45.058443: Epoch   4 Batch 1700/3125   train_loss = 0.790\n",
      "2018-01-15T19:47:46.303514: Epoch   4 Batch 1720/3125   train_loss = 0.877\n",
      "2018-01-15T19:47:47.371575: Epoch   4 Batch 1740/3125   train_loss = 0.917\n",
      "2018-01-15T19:47:48.507640: Epoch   4 Batch 1760/3125   train_loss = 0.878\n",
      "2018-01-15T19:47:49.760712: Epoch   4 Batch 1780/3125   train_loss = 0.859\n",
      "2018-01-15T19:47:50.899777: Epoch   4 Batch 1800/3125   train_loss = 0.797\n",
      "2018-01-15T19:47:51.972839: Epoch   4 Batch 1820/3125   train_loss = 0.848\n",
      "2018-01-15T19:47:52.974896: Epoch   4 Batch 1840/3125   train_loss = 0.872\n",
      "2018-01-15T19:47:54.048957: Epoch   4 Batch 1860/3125   train_loss = 0.905\n",
      "2018-01-15T19:47:55.040014: Epoch   4 Batch 1880/3125   train_loss = 0.870\n",
      "2018-01-15T19:47:56.293086: Epoch   4 Batch 1900/3125   train_loss = 0.766\n",
      "2018-01-15T19:47:57.359147: Epoch   4 Batch 1920/3125   train_loss = 0.839\n",
      "2018-01-15T19:47:58.408207: Epoch   4 Batch 1940/3125   train_loss = 0.779\n",
      "2018-01-15T19:47:59.445266: Epoch   4 Batch 1960/3125   train_loss = 0.710\n",
      "2018-01-15T19:48:00.478325: Epoch   4 Batch 1980/3125   train_loss = 0.791\n",
      "2018-01-15T19:48:01.461381: Epoch   4 Batch 2000/3125   train_loss = 0.998\n",
      "2018-01-15T19:48:02.436437: Epoch   4 Batch 2020/3125   train_loss = 0.863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-01-15T19:48:03.494498: Epoch   4 Batch 2040/3125   train_loss = 0.781\n",
      "2018-01-15T19:48:04.698567: Epoch   4 Batch 2060/3125   train_loss = 0.806\n",
      "2018-01-15T19:48:06.232654: Epoch   4 Batch 2080/3125   train_loss = 0.988\n",
      "2018-01-15T19:48:07.480726: Epoch   4 Batch 2100/3125   train_loss = 0.759\n",
      "2018-01-15T19:48:08.489783: Epoch   4 Batch 2120/3125   train_loss = 0.778\n",
      "2018-01-15T19:48:09.497841: Epoch   4 Batch 2140/3125   train_loss = 0.858\n",
      "2018-01-15T19:48:10.542901: Epoch   4 Batch 2160/3125   train_loss = 0.822\n",
      "2018-01-15T19:48:11.681966: Epoch   4 Batch 2180/3125   train_loss = 0.894\n",
      "2018-01-15T19:48:12.808030: Epoch   4 Batch 2200/3125   train_loss = 0.819\n",
      "2018-01-15T19:48:13.961096: Epoch   4 Batch 2220/3125   train_loss = 0.813\n",
      "2018-01-15T19:48:15.053159: Epoch   4 Batch 2240/3125   train_loss = 0.856\n",
      "2018-01-15T19:48:16.236226: Epoch   4 Batch 2260/3125   train_loss = 0.856\n",
      "2018-01-15T19:48:17.320288: Epoch   4 Batch 2280/3125   train_loss = 0.840\n",
      "2018-01-15T19:48:18.519357: Epoch   4 Batch 2300/3125   train_loss = 0.862\n",
      "2018-01-15T19:48:19.572417: Epoch   4 Batch 2320/3125   train_loss = 0.863\n",
      "2018-01-15T19:48:20.834489: Epoch   4 Batch 2340/3125   train_loss = 0.832\n",
      "2018-01-15T19:48:22.074560: Epoch   4 Batch 2360/3125   train_loss = 0.852\n",
      "2018-01-15T19:48:23.175623: Epoch   4 Batch 2380/3125   train_loss = 0.830\n",
      "2018-01-15T19:48:24.320689: Epoch   4 Batch 2400/3125   train_loss = 0.909\n",
      "2018-01-15T19:48:25.443753: Epoch   4 Batch 2420/3125   train_loss = 0.778\n",
      "2018-01-15T19:48:26.505814: Epoch   4 Batch 2440/3125   train_loss = 0.772\n",
      "2018-01-15T19:48:27.546873: Epoch   4 Batch 2460/3125   train_loss = 0.871\n",
      "2018-01-15T19:48:28.565932: Epoch   4 Batch 2480/3125   train_loss = 0.928\n",
      "2018-01-15T19:48:29.602991: Epoch   4 Batch 2500/3125   train_loss = 0.779\n",
      "2018-01-15T19:48:30.625049: Epoch   4 Batch 2520/3125   train_loss = 0.896\n",
      "2018-01-15T19:48:31.678110: Epoch   4 Batch 2540/3125   train_loss = 0.841\n",
      "2018-01-15T19:48:32.685167: Epoch   4 Batch 2560/3125   train_loss = 0.623\n",
      "2018-01-15T19:48:33.708226: Epoch   4 Batch 2580/3125   train_loss = 0.850\n",
      "2018-01-15T19:48:34.933296: Epoch   4 Batch 2600/3125   train_loss = 0.802\n",
      "2018-01-15T19:48:36.525387: Epoch   4 Batch 2620/3125   train_loss = 0.783\n",
      "2018-01-15T19:48:37.692454: Epoch   4 Batch 2640/3125   train_loss = 0.827\n",
      "2018-01-15T19:48:38.700511: Epoch   4 Batch 2660/3125   train_loss = 0.921\n",
      "2018-01-15T19:48:39.755572: Epoch   4 Batch 2680/3125   train_loss = 0.780\n",
      "2018-01-15T19:48:40.776630: Epoch   4 Batch 2700/3125   train_loss = 0.871\n",
      "2018-01-15T19:48:41.859692: Epoch   4 Batch 2720/3125   train_loss = 0.745\n",
      "2018-01-15T19:48:42.965755: Epoch   4 Batch 2740/3125   train_loss = 0.881\n",
      "2018-01-15T19:48:44.132822: Epoch   4 Batch 2760/3125   train_loss = 0.758\n",
      "2018-01-15T19:48:45.286888: Epoch   4 Batch 2780/3125   train_loss = 0.828\n",
      "2018-01-15T19:48:46.438954: Epoch   4 Batch 2800/3125   train_loss = 1.021\n",
      "2018-01-15T19:48:47.569019: Epoch   4 Batch 2820/3125   train_loss = 1.000\n",
      "2018-01-15T19:48:48.696083: Epoch   4 Batch 2840/3125   train_loss = 0.810\n",
      "2018-01-15T19:48:49.746143: Epoch   4 Batch 2860/3125   train_loss = 0.782\n",
      "2018-01-15T19:48:50.930211: Epoch   4 Batch 2880/3125   train_loss = 0.848\n",
      "2018-01-15T19:48:52.059275: Epoch   4 Batch 2900/3125   train_loss = 0.807\n",
      "2018-01-15T19:48:53.266344: Epoch   4 Batch 2920/3125   train_loss = 0.851\n",
      "2018-01-15T19:48:54.341406: Epoch   4 Batch 2940/3125   train_loss = 0.865\n",
      "2018-01-15T19:48:55.348464: Epoch   4 Batch 2960/3125   train_loss = 0.829\n",
      "2018-01-15T19:48:56.439526: Epoch   4 Batch 2980/3125   train_loss = 0.788\n",
      "2018-01-15T19:48:57.530588: Epoch   4 Batch 3000/3125   train_loss = 0.905\n",
      "2018-01-15T19:48:58.554647: Epoch   4 Batch 3020/3125   train_loss = 0.960\n",
      "2018-01-15T19:48:59.577705: Epoch   4 Batch 3040/3125   train_loss = 0.892\n",
      "2018-01-15T19:49:00.590763: Epoch   4 Batch 3060/3125   train_loss = 0.719\n",
      "2018-01-15T19:49:01.578820: Epoch   4 Batch 3080/3125   train_loss = 0.975\n",
      "2018-01-15T19:49:02.602878: Epoch   4 Batch 3100/3125   train_loss = 1.015\n",
      "2018-01-15T19:49:03.611936: Epoch   4 Batch 3120/3125   train_loss = 0.819\n",
      "2018-01-15T19:49:04.358979: Epoch   4 Batch   16/781   test_loss = 0.777\n",
      "2018-01-15T19:49:04.800004: Epoch   4 Batch   36/781   test_loss = 0.894\n",
      "2018-01-15T19:49:05.513045: Epoch   4 Batch   56/781   test_loss = 0.901\n",
      "2018-01-15T19:49:06.075077: Epoch   4 Batch   76/781   test_loss = 0.979\n",
      "2018-01-15T19:49:06.706113: Epoch   4 Batch   96/781   test_loss = 0.981\n",
      "2018-01-15T19:49:07.169140: Epoch   4 Batch  116/781   test_loss = 0.846\n",
      "2018-01-15T19:49:07.614165: Epoch   4 Batch  136/781   test_loss = 0.794\n",
      "2018-01-15T19:49:08.072191: Epoch   4 Batch  156/781   test_loss = 0.874\n",
      "2018-01-15T19:49:08.504216: Epoch   4 Batch  176/781   test_loss = 0.847\n",
      "2018-01-15T19:49:08.966242: Epoch   4 Batch  196/781   test_loss = 0.785\n",
      "2018-01-15T19:49:09.383266: Epoch   4 Batch  216/781   test_loss = 0.957\n",
      "2018-01-15T19:49:09.850293: Epoch   4 Batch  236/781   test_loss = 0.809\n",
      "2018-01-15T19:49:10.320320: Epoch   4 Batch  256/781   test_loss = 0.851\n",
      "2018-01-15T19:49:10.754345: Epoch   4 Batch  276/781   test_loss = 1.102\n",
      "2018-01-15T19:49:11.220371: Epoch   4 Batch  296/781   test_loss = 0.795\n",
      "2018-01-15T19:49:11.638395: Epoch   4 Batch  316/781   test_loss = 0.823\n",
      "2018-01-15T19:49:12.140424: Epoch   4 Batch  336/781   test_loss = 0.763\n",
      "2018-01-15T19:49:12.705456: Epoch   4 Batch  356/781   test_loss = 0.831\n",
      "2018-01-15T19:49:13.212485: Epoch   4 Batch  376/781   test_loss = 0.871\n",
      "2018-01-15T19:49:13.776518: Epoch   4 Batch  396/781   test_loss = 0.825\n",
      "2018-01-15T19:49:14.357551: Epoch   4 Batch  416/781   test_loss = 0.914\n",
      "2018-01-15T19:49:14.813577: Epoch   4 Batch  436/781   test_loss = 0.872\n",
      "2018-01-15T19:49:15.347607: Epoch   4 Batch  456/781   test_loss = 0.726\n",
      "2018-01-15T19:49:15.816634: Epoch   4 Batch  476/781   test_loss = 0.931\n",
      "2018-01-15T19:49:16.263660: Epoch   4 Batch  496/781   test_loss = 0.942\n",
      "2018-01-15T19:49:16.738687: Epoch   4 Batch  516/781   test_loss = 0.760\n",
      "2018-01-15T19:49:17.205714: Epoch   4 Batch  536/781   test_loss = 0.911\n",
      "2018-01-15T19:49:17.752745: Epoch   4 Batch  556/781   test_loss = 0.788\n",
      "2018-01-15T19:49:18.252774: Epoch   4 Batch  576/781   test_loss = 0.943\n",
      "2018-01-15T19:49:18.698799: Epoch   4 Batch  596/781   test_loss = 0.937\n",
      "2018-01-15T19:49:19.139824: Epoch   4 Batch  616/781   test_loss = 0.916\n",
      "2018-01-15T19:49:19.604851: Epoch   4 Batch  636/781   test_loss = 0.834\n",
      "2018-01-15T19:49:20.034875: Epoch   4 Batch  656/781   test_loss = 0.871\n",
      "2018-01-15T19:49:20.587907: Epoch   4 Batch  676/781   test_loss = 0.996\n",
      "2018-01-15T19:49:21.058934: Epoch   4 Batch  696/781   test_loss = 0.830\n",
      "2018-01-15T19:49:21.636967: Epoch   4 Batch  716/781   test_loss = 0.855\n",
      "2018-01-15T19:49:22.104994: Epoch   4 Batch  736/781   test_loss = 1.050\n",
      "2018-01-15T19:49:22.625024: Epoch   4 Batch  756/781   test_loss = 0.821\n",
      "2018-01-15T19:49:23.054048: Epoch   4 Batch  776/781   test_loss = 0.752\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "losses = {'train':[], 'test':[]}\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    \n",
    "    #搜集数据给tensorBoard用\n",
    "    # Keep track of gradient values and sparsity\n",
    "    '''\n",
    "    grad_summaries = []\n",
    "    for g, v in gradients:\n",
    "        if g is not None:\n",
    "            grad_hist_summary = tf.summary.histogram(\"{}/grad/hist\".format(v.name.replace(':', '_')), g)\n",
    "            sparsity_summary = tf.summary.scalar(\"{}/grad/sparsity\".format(v.name.replace(':', '_')), tf.nn.zero_fraction(g))\n",
    "            grad_summaries.append(grad_hist_summary)\n",
    "            grad_summaries.append(sparsity_summary)\n",
    "    grad_summaries_merged = tf.summary.merge(grad_summaries)\n",
    "        \n",
    "    # Output directory for models and summaries\n",
    "    timestamp = str(int(time.time()))\n",
    "    out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n",
    "    print(\"Writing to {}\\n\".format(out_dir))\n",
    "     \n",
    "    # Summaries for loss and accuracy\n",
    "    loss_summary = tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "    # Train Summaries\n",
    "    train_summary_op = tf.summary.merge([loss_summary, grad_summaries_merged])\n",
    "    train_summary_dir = os.path.join(out_dir, \"summaries\", \"train\")\n",
    "    train_summary_writer = tf.summary.FileWriter(train_summary_dir, sess.graph)\n",
    "\n",
    "    # Inference summaries\n",
    "    inference_summary_op = tf.summary.merge([loss_summary])\n",
    "    inference_summary_dir = os.path.join(out_dir, \"summaries\", \"inference\")\n",
    "    inference_summary_writer = tf.summary.FileWriter(inference_summary_dir, sess.graph)\n",
    "    '''\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver = tf.train.Saver()\n",
    "    for epoch_i in range(num_epochs):\n",
    "        \n",
    "        #将数据集分成训练集和测试集，随机种子不固定\n",
    "        train_X,test_X, train_y, test_y = train_test_split(features,  \n",
    "                                                           targets_values,  \n",
    "                                                           test_size = 0.2,  \n",
    "                                                           random_state = 0)  \n",
    "        \n",
    "        train_batches = get_batches(train_X, train_y, batch_size)\n",
    "        test_batches = get_batches(test_X, test_y, batch_size)\n",
    "    \n",
    "        #训练的迭代，保存训练损失\n",
    "        for batch_i in range(len(train_X) // batch_size):\n",
    "            x, y = next(train_batches)\n",
    "\n",
    "            categories = np.zeros([batch_size, 18])\n",
    "            for i in range(batch_size):\n",
    "                categories[i] = x.take(6,1)[i]\n",
    "\n",
    "            titles = np.zeros([batch_size, sentences_size])\n",
    "            for i in range(batch_size):\n",
    "                titles[i] = x.take(5,1)[i]\n",
    "\n",
    "            feed = {\n",
    "                uid: np.reshape(x.take(0,1), [batch_size, 1]),\n",
    "                user_gender: np.reshape(x.take(2,1), [batch_size, 1]),\n",
    "                user_age: np.reshape(x.take(3,1), [batch_size, 1]),\n",
    "                user_job: np.reshape(x.take(4,1), [batch_size, 1]),\n",
    "                movie_id: np.reshape(x.take(1,1), [batch_size, 1]),\n",
    "                movie_categories: categories,  #x.take(6,1)\n",
    "                movie_titles: titles,  #x.take(5,1)\n",
    "                targets: np.reshape(y, [batch_size, 1]),\n",
    "                dropout_keep_prob: dropout_keep, #dropout_keep\n",
    "                lr: learning_rate}\n",
    "\n",
    "            step, train_loss, _ = sess.run([global_step, loss,train_op], feed)  #cost\n",
    "            losses['train'].append(train_loss)\n",
    "            #train_summary_writer.add_summary(summaries, step)  #\n",
    "            \n",
    "            # Show every <show_every_n_batches> batches\n",
    "            if (epoch_i * (len(train_X) // batch_size) + batch_i) % show_every_n_batches == 0:\n",
    "                time_str = datetime.datetime.now().isoformat()\n",
    "                print('{}: Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
    "                    time_str,\n",
    "                    epoch_i,\n",
    "                    batch_i,\n",
    "                    (len(train_X) // batch_size),\n",
    "                    train_loss))\n",
    "                \n",
    "        #使用测试数据的迭代\n",
    "        for batch_i  in range(len(test_X) // batch_size):\n",
    "            x, y = next(test_batches)\n",
    "            \n",
    "            categories = np.zeros([batch_size, 18])\n",
    "            for i in range(batch_size):\n",
    "                categories[i] = x.take(6,1)[i]\n",
    "\n",
    "            titles = np.zeros([batch_size, sentences_size])\n",
    "            for i in range(batch_size):\n",
    "                titles[i] = x.take(5,1)[i]\n",
    "\n",
    "            feed = {\n",
    "                uid: np.reshape(x.take(0,1), [batch_size, 1]),\n",
    "                user_gender: np.reshape(x.take(2,1), [batch_size, 1]),\n",
    "                user_age: np.reshape(x.take(3,1), [batch_size, 1]),\n",
    "                user_job: np.reshape(x.take(4,1), [batch_size, 1]),\n",
    "                movie_id: np.reshape(x.take(1,1), [batch_size, 1]),\n",
    "                movie_categories: categories,  #x.take(6,1)\n",
    "                movie_titles: titles,  #x.take(5,1)\n",
    "                targets: np.reshape(y, [batch_size, 1]),\n",
    "                dropout_keep_prob: 1,\n",
    "                lr: learning_rate}\n",
    "            \n",
    "            step, test_loss = sess.run([global_step, loss], feed)  #cost\n",
    "\n",
    "            #保存测试损失\n",
    "            losses['test'].append(test_loss)\n",
    "            #inference_summary_writer.add_summary(summaries, step)  #\n",
    "\n",
    "            time_str = datetime.datetime.now().isoformat()\n",
    "            if (epoch_i * (len(test_X) // batch_size) + batch_i) % show_every_n_batches == 0:\n",
    "                print('{}: Epoch {:>3} Batch {:>4}/{}   test_loss = {:.3f}'.format(\n",
    "                    time_str,\n",
    "                    epoch_i,\n",
    "                    batch_i,\n",
    "                    (len(test_X) // batch_size),\n",
    "                    test_loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver.save(sess, save_dir)  #, global_step=epoch_i\n",
    "    print('Model Trained and Saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_params((save_dir))\n",
    "\n",
    "load_dir = load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20036630>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 377
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses['train'], label='Training loss')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2886b320>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 377
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses['test'], label='Test loss')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensors(loaded_graph):\n",
    "\n",
    "    uid = loaded_graph.get_tensor_by_name(\"uid:0\")\n",
    "    user_gender = loaded_graph.get_tensor_by_name(\"user_gender:0\")\n",
    "    user_age = loaded_graph.get_tensor_by_name(\"user_age:0\")\n",
    "    user_job = loaded_graph.get_tensor_by_name(\"user_job:0\")\n",
    "    movie_id = loaded_graph.get_tensor_by_name(\"movie_id:0\")\n",
    "    movie_categories = loaded_graph.get_tensor_by_name(\"movie_categories:0\")\n",
    "    movie_titles = loaded_graph.get_tensor_by_name(\"movie_titles:0\")\n",
    "    targets = loaded_graph.get_tensor_by_name(\"targets:0\")\n",
    "    dropout_keep_prob = loaded_graph.get_tensor_by_name(\"dropout_keep_prob:0\")\n",
    "    lr = loaded_graph.get_tensor_by_name(\"LearningRate:0\")\n",
    "    #两种不同计算预测评分的方案使用不同的name获取tensor inference\n",
    "    inference = loaded_graph.get_tensor_by_name(\"inference/inference/BiasAdd:0\")\n",
    "    #inference = loaded_graph.get_tensor_by_name(\"inference/MatMul:0\")#\n",
    "    movie_combine_layer_flat = loaded_graph.get_tensor_by_name(\"movie_fc/Reshape:0\")\n",
    "    user_combine_layer_flat = loaded_graph.get_tensor_by_name(\"user_fc/Reshape:0\")\n",
    "    return uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, targets, lr, dropout_keep_prob, inference, movie_combine_layer_flat, user_combine_layer_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#指定用户和电影进行评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正向传播，预测评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_movie(user_id_val, movie_id_val):\n",
    "    loaded_graph = tf.Graph()  #\n",
    "    with tf.Session(graph=loaded_graph) as sess:  #\n",
    "        # Load saved model\n",
    "        loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "        loader.restore(sess, load_dir)\n",
    "    \n",
    "        # Get Tensors from loaded model\n",
    "        uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, targets, lr, dropout_keep_prob, inference,_, __ = get_tensors(loaded_graph)  #loaded_graph\n",
    "    \n",
    "        categories = np.zeros([1, 18])\n",
    "        categories[0] = movies.values[movieid2idx[movie_id_val]][2]\n",
    "    \n",
    "        titles = np.zeros([1, sentences_size])\n",
    "        titles[0] = movies.values[movieid2idx[movie_id_val]][1]\n",
    "    \n",
    "        feed = {\n",
    "              uid: np.reshape(users.values[user_id_val-1][0], [1, 1]),\n",
    "              user_gender: np.reshape(users.values[user_id_val-1][1], [1, 1]),\n",
    "              user_age: np.reshape(users.values[user_id_val-1][2], [1, 1]),\n",
    "              user_job: np.reshape(users.values[user_id_val-1][3], [1, 1]),\n",
    "              movie_id: np.reshape(movies.values[movieid2idx[movie_id_val]][0], [1, 1]),\n",
    "              movie_categories: categories,  #x.take(6,1)\n",
    "              movie_titles: titles,  #x.take(5,1)\n",
    "              dropout_keep_prob: 1}\n",
    "    \n",
    "        # Get Prediction\n",
    "        inference_val = sess.run([inference], feed)  \n",
    "    \n",
    "        return (inference_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 3.16517735]], dtype=float32)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_movie(234, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 4.27231884]], dtype=float32)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_movie(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 3.56507564]], dtype=float32)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_movie(1,661)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 2.69281101]], dtype=float32)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_movie(4490,2526)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成电影特征矩阵并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n"
     ]
    }
   ],
   "source": [
    "loaded_graph = tf.Graph()  #\n",
    "movie_matrics = []\n",
    "with tf.Session(graph=loaded_graph) as sess:  #\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "\n",
    "    # Get Tensors from loaded model\n",
    "    uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, targets, lr, dropout_keep_prob, _, movie_combine_layer_flat, __ = get_tensors(loaded_graph)  #loaded_graph\n",
    "\n",
    "    for item in movies.values:\n",
    "        categories = np.zeros([1, 18])\n",
    "        categories[0] = item.take(2)\n",
    "\n",
    "        titles = np.zeros([1, sentences_size])\n",
    "        titles[0] = item.take(1)\n",
    "\n",
    "        feed = {\n",
    "            movie_id: np.reshape(item.take(0), [1, 1]),\n",
    "            movie_categories: categories,  #x.take(6,1)\n",
    "            movie_titles: titles,  #x.take(5,1)\n",
    "            dropout_keep_prob: 1}\n",
    "\n",
    "        movie_combine_layer_flat_val = sess.run([movie_combine_layer_flat], feed)  \n",
    "        movie_matrics.append(movie_combine_layer_flat_val)\n",
    "\n",
    "pickle.dump((np.array(movie_matrics).reshape(-1, 200)), open('movie_matrics.p', 'wb'))\n",
    "movie_matrics = pickle.load(open('movie_matrics.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成用户特征矩阵并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n"
     ]
    }
   ],
   "source": [
    "loaded_graph = tf.Graph()  #\n",
    "users_matrics = []\n",
    "with tf.Session(graph=loaded_graph) as sess:  #\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "    loader.restore(sess, load_dir)\n",
    "\n",
    "    # Get Tensors from loaded model\n",
    "    uid, user_gender, user_age, user_job, movie_id, movie_categories, movie_titles, targets, lr, dropout_keep_prob, _, __,user_combine_layer_flat = get_tensors(loaded_graph)  #loaded_graph\n",
    "\n",
    "    for item in users.values:\n",
    "\n",
    "        feed = {\n",
    "            uid: np.reshape(item.take(0), [1, 1]),\n",
    "            user_gender: np.reshape(item.take(1), [1, 1]),\n",
    "            user_age: np.reshape(item.take(2), [1, 1]),\n",
    "            user_job: np.reshape(item.take(3), [1, 1]),\n",
    "            dropout_keep_prob: 1}\n",
    "\n",
    "        user_combine_layer_flat_val = sess.run([user_combine_layer_flat], feed)  \n",
    "        users_matrics.append(user_combine_layer_flat_val)\n",
    "\n",
    "pickle.dump((np.array(users_matrics).reshape(-1, 200)), open('users_matrics.p', 'wb'))\n",
    "users_matrics = pickle.load(open('users_matrics.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_matrics = pickle.load(open('users_matrics.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#开始推荐\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_same_type_movie(movie_id_val, top_k = 20):\n",
    "    \n",
    "    loaded_graph = tf.Graph()  #\n",
    "    with tf.Session(graph=loaded_graph) as sess:  #\n",
    "        # Load saved model\n",
    "        loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "        loader.restore(sess, load_dir)\n",
    "        #余弦相似度\n",
    "        norm_movie_matrics = tf.sqrt(tf.reduce_sum(tf.square(movie_matrics), 1, keep_dims=True))\n",
    "        normalized_movie_matrics = movie_matrics / norm_movie_matrics\n",
    "\n",
    "        #推荐同类型的电影\n",
    "        probs_embeddings = (movie_matrics[movieid2idx[movie_id_val]]).reshape([1, 200])\n",
    "        #=.transpose()转置函数\n",
    "        probs_similarity = tf.matmul(probs_embeddings, tf.transpose(normalized_movie_matrics))\n",
    "        sim = (probs_similarity.eval())\n",
    "    #     results = (-sim[0]).argsort()[0:top_k]\n",
    "    #     print(results)\n",
    "        \n",
    "        print(\"您看的电影是：{}\".format(movies_orig[movieid2idx[movie_id_val]]))\n",
    "        print(\"以下是给您的推荐：\")\n",
    "        p = np.squeeze(sim)\n",
    "        #argsort函数返回的是数组值从小到大的索引值\n",
    "        p[np.argsort(p)[:-top_k]] = 0\n",
    "        p = p / np.sum(p)\n",
    "        results = set()\n",
    "        while len(results) != 5:\n",
    "            c = np.random.choice(3883, 1, p=p)[0]\n",
    "            results.add(c)\n",
    "        for val in (results):\n",
    "            print(val)\n",
    "            print(movies_orig[val])\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n",
      "您看的电影是：[1401 'Ghosts of Mississippi (1996)' 'Drama']\n",
      "以下是给您的推荐：\n",
      "2241\n",
      "[2310 'Mighty, The (1998)' 'Drama']\n",
      "802\n",
      "[812 'Magic Hunter (1994)' 'Drama']\n",
      "617\n",
      "[621 'My Favorite Season (1993)' 'Drama']\n",
      "2990\n",
      "[3059 'British Intelligence (1940)' 'Drama']\n",
      "3342\n",
      "[3411 'Babymother (1998)' 'Drama']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{617, 802, 2241, 2990, 3342}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_same_type_movie(1401, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#推荐你喜欢的电影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_your_favorite_movie(user_id_val, top_k = 10):\n",
    "\n",
    "    loaded_graph = tf.Graph()  #\n",
    "    with tf.Session(graph=loaded_graph) as sess:  #\n",
    "        # Load saved model\n",
    "        loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "        loader.restore(sess, load_dir)\n",
    "\n",
    "        #推荐您喜欢的电影\n",
    "        probs_embeddings = (users_matrics[user_id_val-1]).reshape([1, 200])\n",
    "\n",
    "        probs_similarity = tf.matmul(probs_embeddings, tf.transpose(movie_matrics))\n",
    "        sim = (probs_similarity.eval())\n",
    "    #     print(sim.shape)\n",
    "    #     results = (-sim[0]).argsort()[0:top_k]\n",
    "    #     print(results)\n",
    "        \n",
    "    #     sim_norm = probs_norm_similarity.eval()\n",
    "    #     print((-sim_norm[0]).argsort()[0:top_k])\n",
    "    \n",
    "        print(\"以下是给您的推荐：\")\n",
    "        p = np.squeeze(sim)\n",
    "        p[np.argsort(p)[:-top_k]] = 0\n",
    "        p = p / np.sum(p)\n",
    "        results = set()\n",
    "        while len(results) != 5:\n",
    "            c = np.random.choice(3883, 1, p=p)[0]\n",
    "            results.add(c)\n",
    "        for val in (results):\n",
    "            print(val)\n",
    "            print(movies_orig[val])\n",
    "\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n",
      "以下是给您的推荐：\n",
      "1959\n",
      "[2028 'Saving Private Ryan (1998)' 'Action|Drama|War']\n",
      "1178\n",
      "[1196 'Star Wars: Episode V - The Empire Strikes Back (1980)'\n",
      " 'Action|Adventure|Drama|Sci-Fi|War']\n",
      "1613\n",
      "[1659 'Hurricane Streets (1998)' 'Drama']\n",
      "1726\n",
      "[1784 'As Good As It Gets (1997)' 'Comedy|Drama']\n",
      "2663\n",
      "[2732 'Jules and Jim (Jules et Jim) (1961)' 'Drama']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1178, 1613, 1726, 1959, 2663}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_your_favorite_movie(234, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#喜欢这个电影的人还喜欢那些电影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def recommend_other_favorite_movie(movie_id_val, top_k = 20):\n",
    "    loaded_graph = tf.Graph()  #\n",
    "    with tf.Session(graph=loaded_graph) as sess:  #\n",
    "        # Load saved model\n",
    "        loader = tf.train.import_meta_graph(load_dir + '.meta')\n",
    "        loader.restore(sess, load_dir)\n",
    "\n",
    "        probs_movie_embeddings = (movie_matrics[movieid2idx[movie_id_val]]).reshape([1, 200])\n",
    "        probs_user_favorite_similarity = tf.matmul(probs_movie_embeddings, tf.transpose(users_matrics))\n",
    "        favorite_user_id = np.argsort(probs_user_favorite_similarity.eval())[0][-top_k:]\n",
    "    #     print(normalized_users_matrics.eval().shape)\n",
    "    #     print(probs_user_favorite_similarity.eval()[0][favorite_user_id])\n",
    "    #     print(favorite_user_id.shape)\n",
    "    \n",
    "        print(\"您看的电影是：{}\".format(movies_orig[movieid2idx[movie_id_val]]))\n",
    "        \n",
    "        print(\"喜欢看这个电影的人是：{}\".format(users_orig[favorite_user_id-1]))\n",
    "        probs_users_embeddings = (users_matrics[favorite_user_id-1]).reshape([-1, 200])\n",
    "        probs_similarity = tf.matmul(probs_users_embeddings, tf.transpose(movie_matrics))\n",
    "        sim = (probs_similarity.eval())\n",
    "    #     results = (-sim[0]).argsort()[0:top_k]\n",
    "    #     print(results)\n",
    "    \n",
    "    #     print(sim.shape)\n",
    "    #     print(np.argmax(sim, 1))\n",
    "        p = np.argmax(sim, 1)\n",
    "        print(\"喜欢看这个电影的人还喜欢看：\")\n",
    "\n",
    "        results = set()\n",
    "        while len(results) != 5:\n",
    "            c = p[random.randrange(top_k)]\n",
    "            results.add(c)\n",
    "        for val in (results):\n",
    "            print(val)\n",
    "            print(movies_orig[val])\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save\n",
      "您看的电影是：[1401 'Ghosts of Mississippi (1996)' 'Drama']\n",
      "喜欢看这个电影的人是：[[197 'M' 18 14]\n",
      " [238 'F' 50 7]\n",
      " [5346 'F' 25 3]\n",
      " [5164 'F' 35 17]\n",
      " [3257 'M' 25 14]\n",
      " [937 'M' 25 15]\n",
      " [5630 'M' 35 17]\n",
      " [4117 'M' 18 4]\n",
      " [4971 'M' 35 7]\n",
      " [5591 'M' 18 0]\n",
      " [4153 'M' 50 17]\n",
      " [2718 'F' 25 4]\n",
      " [4262 'F' 35 6]\n",
      " [2758 'M' 56 8]\n",
      " [2267 'F' 56 13]\n",
      " [5427 'M' 35 19]\n",
      " [5520 'M' 45 1]\n",
      " [148 'M' 50 17]\n",
      " [4520 'M' 25 4]\n",
      " [4012 'M' 18 4]]\n",
      "喜欢看这个电影的人还喜欢看：\n",
      "2752\n",
      "[2821 'Male and Female (1919)' 'Adventure|Drama']\n",
      "2881\n",
      "[2950 'Blue Lagoon, The (1980)' 'Adventure|Drama|Romance']\n",
      "1688\n",
      "[1739 '3 Ninjas: High Noon On Mega Mountain (1998)' \"Action|Children's\"]\n",
      "2358\n",
      "[2427 'Thin Red Line, The (1998)' 'Action|Drama|War']\n",
      "2353\n",
      "[2422 'Karate Kid III, The (1989)' 'Action|Adventure|Drama']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1688, 2353, 2358, 2752, 2881}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_other_favorite_movie(1401, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
